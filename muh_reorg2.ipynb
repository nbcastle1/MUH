{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "217d5fd3-6c9d-4c53-8aac-a5de3902599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENHANCED MOTOR LEARNING ANALYSIS WITH STRIDE CHANGE DISTRIBUTION\n",
    "# Incorporates the stride change distribution plotting functionality\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import tempfile\n",
    "import webbrowser\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, mannwhitneyu, gaussian_kde\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, accuracy_score, \n",
    "                             precision_score, recall_score, f1_score, \n",
    "                             roc_auc_score, confusion_matrix, roc_curve)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from scipy.stats import gaussian_kde, pearsonr, mannwhitneyu, ttest_ind, f_oneway\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f17b028b-f0a9-4cb1-bd4a-a59726b15c54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 1. CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Enhanced configuration settings for the motor learning analysis.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_output_dir: str = 'motor_learning_output'):\n",
    "        # Base directory for all outputs\n",
    "        self.BASE_OUTPUT_DIR = Path(base_output_dir)\n",
    "        self.BASE_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Create organized subdirectory structure\n",
    "        self.FIGURES_DIR = self.BASE_OUTPUT_DIR / 'figures'\n",
    "        self.INDIVIDUAL_PLOTS_DIR = self.FIGURES_DIR / 'individual_plots'\n",
    "        self.POPULATION_PLOTS_DIR = self.FIGURES_DIR / 'population_plots'\n",
    "        self.STATISTICAL_PLOTS_DIR = self.FIGURES_DIR / 'statistical_plots'\n",
    "        self.REPORTS_DIR = self.BASE_OUTPUT_DIR / 'reports'\n",
    "        self.EXPORTS_DIR = self.BASE_OUTPUT_DIR / 'exports'\n",
    "        self.PROCESSED_DATA_DIR = self.BASE_OUTPUT_DIR / 'processed_data'\n",
    "        \n",
    "        # Create all directories\n",
    "        for directory in [self.FIGURES_DIR, self.INDIVIDUAL_PLOTS_DIR, \n",
    "                         self.POPULATION_PLOTS_DIR, self.STATISTICAL_PLOTS_DIR,\n",
    "                         self.REPORTS_DIR, self.EXPORTS_DIR, self.PROCESSED_DATA_DIR]:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # File processing parameters\n",
    "        self.MIN_COMPLETE_STRIDES = 20\n",
    "        self.PROCESSED_DATA_FILE = self.PROCESSED_DATA_DIR / 'processed_data.pkl'\n",
    "        \n",
    "        # Trial type mappings\n",
    "        self.TRIAL_TYPE_MAPPING = {\n",
    "            'primer': 'vis1',\n",
    "            'trial': 'invis', \n",
    "            'vis': 'vis2',\n",
    "            'pref': 'pref'\n",
    "        }\n",
    "        \n",
    "        # Analysis parameters\n",
    "        self.MOTOR_NOISE_STRIDES = 20\n",
    "        self.MOTOR_NOISE_THRESHOLD = 0.3\n",
    "        self.SUCCESS_RATE_THRESHOLD = 0.68\n",
    "        self.TARGET_SIZE_THRESHOLD = 0.31\n",
    "        self.MAX_STRIDES_THRESHOLD = 415\n",
    "        \n",
    "        # Visualization parameters\n",
    "        self.FIGURE_DPI = 300\n",
    "        self.ALPHA_LEVEL = 0.05\n",
    "        self.AGE_BINS = [7, 10, 13, 16, 18]\n",
    "        self.AGE_LABELS = ['7-10', '10-13', '13-16', '16-18']\n",
    "        \n",
    "        print(f\"📁 Config initialized with base directory: {self.BASE_OUTPUT_DIR}\")\n",
    "        print(f\"   📊 Figures: {self.FIGURES_DIR}\")\n",
    "        print(f\"   📋 Reports: {self.REPORTS_DIR}\")\n",
    "        print(f\"   💾 Exports: {self.EXPORTS_DIR}\")\n",
    "\n",
    "    def get_figure_path(self, filename: str, subdir: str = 'general') -> Path:\n",
    "        \"\"\"Get standardized figure path with automatic subdirectory creation.\"\"\"\n",
    "        if subdir == 'individual':\n",
    "            target_dir = self.INDIVIDUAL_PLOTS_DIR\n",
    "        elif subdir == 'population':\n",
    "            target_dir = self.POPULATION_PLOTS_DIR\n",
    "        elif subdir == 'statistical':\n",
    "            target_dir = self.STATISTICAL_PLOTS_DIR\n",
    "        else:\n",
    "            target_dir = self.FIGURES_DIR\n",
    "        \n",
    "        target_dir.mkdir(parents=True, exist_ok=True)\n",
    "        return target_dir / filename\n",
    "    \n",
    "    def get_report_path(self, filename: str) -> Path:\n",
    "        \"\"\"Get standardized report path.\"\"\"\n",
    "        return self.REPORTS_DIR / filename\n",
    "    \n",
    "    def get_export_path(self, filename: str) -> Path:\n",
    "        \"\"\"Get standardized export path.\"\"\"\n",
    "        return self.EXPORTS_DIR / filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef0725fd-e206-4ee8-ab35-2ad451620009",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 2. UTILITY FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "class DataUtils:\n",
    "    \"\"\"Utility functions for data processing.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_and_validate_file(file_path: Path, required_cols: set = None) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Load and validate a single data file.\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep='\\t')\n",
    "            \n",
    "            if required_cols and not required_cols.issubset(df.columns):\n",
    "                return None\n",
    "                \n",
    "            # Basic cleaning\n",
    "            if 'Stride Number' in df.columns:\n",
    "                df['Stride Number'] = pd.to_numeric(df['Stride Number'], errors='coerce')\n",
    "                df = df.dropna(subset=['Stride Number'])\n",
    "                df = df.drop_duplicates(subset=['Stride Number'])\n",
    "            \n",
    "            return df if not df.empty else None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading {file_path.name}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_anomalies(df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict]:\n",
    "        \"\"\"Detect and flag anomalies in stride data.\"\"\"\n",
    "        if df is None or df.empty:\n",
    "            return df, {}\n",
    "\n",
    "        df = df.copy()\n",
    "        df['Anomalous'] = False\n",
    "        anomalies = {}\n",
    "\n",
    "        # Time-based anomalies\n",
    "        time_col = next((col for col in ['Time', 'Timestamp', 'Time (s)'] \n",
    "                        if col in df.columns), None)\n",
    "        if time_col:\n",
    "            df[time_col] = pd.to_numeric(df[time_col], errors='coerce')\n",
    "            time_diff = df[time_col].diff()\n",
    "            jump_mask = time_diff > time_diff.quantile(0.99) * 5\n",
    "            \n",
    "            for idx in df.index[jump_mask.fillna(False)]:\n",
    "                df.at[idx, 'Anomalous'] = True\n",
    "                anomalies.setdefault(idx, []).append('time_jump')\n",
    "\n",
    "        # Sum of gains and steps anomalies\n",
    "        if 'Sum of gains and steps' in df.columns:\n",
    "            high_mask = df['Sum of gains and steps'] > 4\n",
    "            zero_mask = df['Sum of gains and steps'] == 0\n",
    "\n",
    "            for idx in df.index[high_mask]:\n",
    "                df.at[idx, 'Anomalous'] = True\n",
    "                anomalies.setdefault(idx, []).append('sum_gain_step_high')\n",
    "            \n",
    "            for idx in df.index[zero_mask]:\n",
    "                df.at[idx, 'Anomalous'] = True\n",
    "                anomalies.setdefault(idx, []).append('sum_gain_step_zero')\n",
    "\n",
    "        # Duplicate rows\n",
    "        duplicated_mask = df.duplicated()\n",
    "        for idx in df.index[duplicated_mask]:\n",
    "            df.at[idx, 'Anomalous'] = True\n",
    "            anomalies.setdefault(idx, []).append('duplicate_row')\n",
    "\n",
    "        return df, anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbbaa9d3-4239-477d-a5dc-d824c0684962",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 3. TRIAL PROCESSING\n",
    "# ==============================================================================\n",
    "\n",
    "class TrialProcessor:\n",
    "    \"\"\"Handles loading, combining, and processing of trial data.\"\"\"\n",
    "    \n",
    "    def __init__(self, debug: bool = True):\n",
    "        self.debug = debug\n",
    "        \n",
    "    def find_and_combine_trial_files(self, subject_dir: Path, trial_prefix: str) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Find and combine trial files for a given trial type.\"\"\"\n",
    "        all_files = sorted(subject_dir.glob(f\"{trial_prefix}*.txt\"))\n",
    "        \n",
    "        if not all_files:\n",
    "            if self.debug:\n",
    "                print(f\"  ⚠️ No files found for {trial_prefix}\")\n",
    "            return None\n",
    "        \n",
    "        # Special handling for preference trials\n",
    "        if trial_prefix == 'pref':\n",
    "            return self._handle_pref_trial(all_files)\n",
    "        \n",
    "        # Single file case\n",
    "        if len(all_files) == 1:\n",
    "            return DataUtils.load_and_validate_file(all_files[0])\n",
    "        \n",
    "        # Multiple files - combine them\n",
    "        return self._combine_trial_fragments(all_files)\n",
    "    \n",
    "    def _handle_pref_trial(self, files: List[Path]) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Handle preference trial - select largest file.\"\"\"\n",
    "        largest_file = max(files, key=lambda f: f.stat().st_size)\n",
    "        if self.debug and len(files) > 1:\n",
    "            print(f\"  ⚡ pref trial - selected largest of {len(files)} files\")\n",
    "        return DataUtils.load_and_validate_file(largest_file)\n",
    "    \n",
    "    def _combine_trial_fragments(self, files: List[Path]) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Combine multiple trial fragments intelligently.\"\"\"\n",
    "        file_info = []\n",
    "        \n",
    "        for f in files:\n",
    "            try:\n",
    "                with open(f, 'r') as file:\n",
    "                    header = file.readline().strip().split('\\t')\n",
    "                    stride_col = next((i for i, col in enumerate(header) \n",
    "                                     if 'stride' in col.lower() and \n",
    "                                     ('num' in col.lower() or 'no' in col.lower())), None)\n",
    "                    \n",
    "                    if stride_col is None:\n",
    "                        continue\n",
    "                    \n",
    "                    # Get stride range\n",
    "                    lines = file.readlines()\n",
    "                    first_stride = float(lines[0].split('\\t')[stride_col])\n",
    "                    last_stride = float(lines[-1].split('\\t')[stride_col])\n",
    "                    \n",
    "                    file_info.append({\n",
    "                        'path': f,\n",
    "                        'first': first_stride,\n",
    "                        'last': last_stride,\n",
    "                        'size': f.stat().st_size\n",
    "                    })\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        if not file_info:\n",
    "            return DataUtils.load_and_validate_file(max(files, key=lambda f: f.stat().st_size))\n",
    "        \n",
    "        # Find best continuous sequence\n",
    "        file_info.sort(key=lambda x: x['first'])\n",
    "        best_sequence = self._find_best_sequence(file_info)\n",
    "        \n",
    "        if len(best_sequence) >= 2:\n",
    "            return self._merge_files([f['path'] for f in best_sequence])\n",
    "        \n",
    "        # Fallback to largest file\n",
    "        return DataUtils.load_and_validate_file(max(file_info, key=lambda x: x['size'])['path'])\n",
    "    \n",
    "    def _find_best_sequence(self, file_info: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Find the best continuous sequence of files.\"\"\"\n",
    "        best_sequence = []\n",
    "        current_sequence = [file_info[0]]\n",
    "        \n",
    "        for file_data in file_info[1:]:\n",
    "            if file_data['first'] == current_sequence[-1]['last'] + 1:\n",
    "                current_sequence.append(file_data)\n",
    "            else:\n",
    "                if len(current_sequence) > len(best_sequence):\n",
    "                    best_sequence = current_sequence\n",
    "                current_sequence = [file_data]\n",
    "        \n",
    "        return max([best_sequence, current_sequence], key=len)\n",
    "    \n",
    "    def _merge_files(self, file_paths: List[Path]) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Merge multiple files into a single DataFrame.\"\"\"\n",
    "        dfs = []\n",
    "        for f in file_paths:\n",
    "            df = DataUtils.load_and_validate_file(f)\n",
    "            if df is not None:\n",
    "                dfs.append(df)\n",
    "        \n",
    "        if not dfs:\n",
    "            return None\n",
    "        \n",
    "        combined = pd.concat(dfs, ignore_index=True)\n",
    "        \n",
    "        # Clean and sort\n",
    "        if 'Stride Number' in combined.columns:\n",
    "            combined = combined.sort_values('Stride Number')\n",
    "            combined = combined.drop_duplicates('Stride Number')\n",
    "        \n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c737c435-0348-4a95-9052-77cc5cb51e36",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 4. MAIN DATA MANAGER\n",
    "# ==============================================================================\n",
    "\n",
    "class MotorLearningDataManager:\n",
    "    \"\"\"Updated to use centralized config.\"\"\"\n",
    "    \n",
    "    def __init__(self, metadata_path: str, data_root_dir: str, \n",
    "                 config: Config = None, force_reprocess: bool = False, debug: bool = True):\n",
    "        self.metadata_path = metadata_path\n",
    "        self.data_root_dir = data_root_dir\n",
    "        self.debug = debug\n",
    "        \n",
    "        # KEY CHANGE: Use provided config or create default\n",
    "        self.config = config if config else Config()\n",
    "        \n",
    "        # Initialize components (unchanged)\n",
    "        self.trial_processor = TrialProcessor(debug=debug)\n",
    "        \n",
    "        # Data storage (unchanged)\n",
    "        self.metadata = None\n",
    "        self.processed_data = {}\n",
    "        \n",
    "        # KEY CHANGE: Use config for processed data file path\n",
    "        if not force_reprocess and self.config.PROCESSED_DATA_FILE.exists():\n",
    "            self._load_processed_data()\n",
    "        else:\n",
    "            self._process_all_data()\n",
    "            self._save_processed_data()\n",
    "    \n",
    "    def _load_processed_data(self):\n",
    "        \"\"\"Updated to use config path.\"\"\"\n",
    "        with open(self.config.PROCESSED_DATA_FILE, 'rb') as f:\n",
    "            self.processed_data = pickle.load(f)\n",
    "            \n",
    "        # Rebuild metadata DataFrame (unchanged)\n",
    "        self.metadata = pd.DataFrame.from_dict(\n",
    "            {subj: data['metadata'] for subj, data in self.processed_data.items()}, \n",
    "            orient='index'\n",
    "        )\n",
    "    \n",
    "    def _save_processed_data(self):\n",
    "        \"\"\"Updated to use config path.\"\"\"\n",
    "        with open(self.config.PROCESSED_DATA_FILE, 'wb') as f:\n",
    "            pickle.dump(self.processed_data, f)\n",
    "    \n",
    "    def _process_all_data(self):\n",
    "        \"\"\"Process all subject data.\"\"\"\n",
    "        self._load_metadata()\n",
    "        total_subjects = len(self.metadata)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"🔄 Processing {total_subjects} subjects...\")\n",
    "        \n",
    "        for i, (_, row) in enumerate(self.metadata.iterrows(), 1):\n",
    "            subject_id = row['ID']\n",
    "            if self.debug:\n",
    "                print(f\"\\n[{i}/{total_subjects}] Processing {subject_id}...\")\n",
    "            \n",
    "            subject_data = self._process_subject_data(subject_id, row)\n",
    "            if subject_data:\n",
    "                self.processed_data[subject_id] = subject_data\n",
    "    \n",
    "    def _load_metadata(self):\n",
    "        \"\"\"Load and clean metadata.\"\"\"\n",
    "        self.metadata = pd.read_csv(self.metadata_path)\n",
    "        self.metadata['DOB'] = pd.to_datetime(self.metadata['DOB'], errors='coerce')\n",
    "        self.metadata['Session Date'] = pd.to_datetime(self.metadata['Session Date'], errors='coerce')\n",
    "        self.metadata = self.metadata.dropna(subset=['ID', 'age_months'])\n",
    "    \n",
    "    def _process_subject_data(self, subject_id: str, metadata_row: pd.Series) -> Optional[Dict]:\n",
    "        \"\"\"Process data for a single subject.\"\"\"\n",
    "        subject_dir = Path(self.data_root_dir) / subject_id\n",
    "        if not subject_dir.exists():\n",
    "            if self.debug:\n",
    "                print(f\"❌ Directory not found: {subject_dir}\")\n",
    "            return None\n",
    "        \n",
    "        trial_data = {}\n",
    "        \n",
    "        for original_type in ['primer', 'trial', 'vis', 'pref']:\n",
    "            try:\n",
    "                # Load trial data\n",
    "                df = self.trial_processor.find_and_combine_trial_files(subject_dir, original_type)\n",
    "                \n",
    "                if df is not None:\n",
    "                    # Process the data\n",
    "                    processed_df, anomalies = self._process_trial_data(df, original_type)\n",
    "                    \n",
    "                    # Store with mapped name\n",
    "                    new_type = self.config.TRIAL_TYPE_MAPPING[original_type]\n",
    "                    trial_data[new_type] = {\n",
    "                        'data': processed_df,\n",
    "                        'anomalies': anomalies\n",
    "                    }\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {subject_id}/{original_type}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return {\n",
    "            'metadata': metadata_row.to_dict(),\n",
    "            'trial_data': trial_data\n",
    "        } if trial_data else None\n",
    "    \n",
    "    def _process_trial_data(self, df: pd.DataFrame, trial_type: str) -> Tuple[pd.DataFrame, Dict]:\n",
    "        \"\"\"Process trial data and calculate metrics.\"\"\"\n",
    "        if df is None or df.empty:\n",
    "            return None, {}\n",
    "        \n",
    "        # Skip processing for pref trials (just clean duplicates)\n",
    "        if trial_type == 'pref':\n",
    "            df = df.drop_duplicates(subset='Left heel strike', keep='last')\n",
    "            return df, {}\n",
    "        \n",
    "        # Validate required columns\n",
    "        required_cols = ['Stride Number', 'Success', 'Upper bound success', \n",
    "                        'Lower bound success', 'Constant']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"Missing required columns: {missing_cols}\")\n",
    "            return None, {}\n",
    "        \n",
    "        try:\n",
    "            # Process trial data\n",
    "            df = df.sort_values('Stride Number')\n",
    "            df['Target size'] = df['Upper bound success'] - df['Lower bound success']\n",
    "            df = df.drop_duplicates(subset='Stride Number', keep='last')\n",
    "            \n",
    "            # Scale sum of gains and steps\n",
    "            if 'Sum of gains and steps' in df.columns:\n",
    "                df['Sum of gains and steps'] = 1.5 * df['Sum of gains and steps']\n",
    "            \n",
    "            # Detect anomalies\n",
    "            df, anomalies = DataUtils.detect_anomalies(df)\n",
    "            \n",
    "            return df, anomalies\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {trial_type} data: {str(e)}\")\n",
    "            return None, {}\n",
    "    \n",
    "    def get_trial_df(self, trial_dict: Dict) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Get trial data from trial dictionary.\"\"\"\n",
    "        if trial_dict and 'data' in trial_dict:\n",
    "            return trial_dict['data']\n",
    "        return None\n",
    "    \n",
    "    def filter_trials(self, max_target_size=None, min_age=None, max_age=None, \n",
    "                     required_trial_types=None, min_strides=None, max_strides=None):\n",
    "        \"\"\"Filter trials based on specified criteria.\"\"\"\n",
    "        filtered_data = {}\n",
    "        \n",
    "        for subject_id, subject_data in self.processed_data.items():\n",
    "            # SIMPLIFIED AGE FILTERING - always use age_months/12\n",
    "            age = subject_data['metadata']['age_months'] / 12\n",
    "            if min_age is not None and age < min_age:\n",
    "                continue\n",
    "            if max_age is not None and age > max_age:\n",
    "                continue\n",
    "            \n",
    "            # Check required trial types\n",
    "            if required_trial_types:\n",
    "                missing_trials = [\n",
    "                    t for t in required_trial_types \n",
    "                    if t not in subject_data['trial_data'] or \n",
    "                       subject_data['trial_data'][t] is None or\n",
    "                       subject_data['trial_data'][t]['data'] is None\n",
    "                ]\n",
    "                if missing_trials:\n",
    "                    continue\n",
    "            \n",
    "            # Check other criteria\n",
    "            valid_subject = True\n",
    "            filtered_trial_data = {}\n",
    "            \n",
    "            for trial_type, trial_dict in subject_data['trial_data'].items():\n",
    "                if trial_dict and trial_dict['data'] is not None:\n",
    "                    df = trial_dict['data']\n",
    "                    \n",
    "                    # Apply filters\n",
    "                    if (max_target_size is not None and \n",
    "                        'Target size' in df.columns and \n",
    "                        df['Target size'].min() > max_target_size):\n",
    "                        valid_subject = False\n",
    "                        break\n",
    "                    \n",
    "                    n_strides = len(df)\n",
    "                    if ((min_strides is not None and n_strides < min_strides) or\n",
    "                        (max_strides is not None and n_strides > max_strides)):\n",
    "                        valid_subject = False\n",
    "                        break\n",
    "                    \n",
    "                    # Include valid trial\n",
    "                    filtered_trial_data[trial_type] = {\n",
    "                        'data': df.copy(),\n",
    "                        'anomalies': trial_dict['anomalies'].copy()\n",
    "                    }\n",
    "            \n",
    "            if valid_subject and filtered_trial_data:\n",
    "                filtered_data[subject_id] = {\n",
    "                    'metadata': subject_data['metadata'].copy(),\n",
    "                    'trial_data': filtered_trial_data\n",
    "                }\n",
    "        \n",
    "        # Create new instance with filtered data\n",
    "        new_instance = MotorLearningDataManager.__new__(MotorLearningDataManager)\n",
    "        new_instance.config = self.config\n",
    "        new_instance.trial_processor = self.trial_processor\n",
    "        new_instance.metadata_path = self.metadata_path\n",
    "        new_instance.data_root_dir = self.data_root_dir\n",
    "        new_instance.debug = self.debug\n",
    "        new_instance.processed_data = filtered_data\n",
    "        new_instance.metadata = pd.DataFrame.from_dict(\n",
    "            {subj: data['metadata'] for subj, data in filtered_data.items()}, \n",
    "            orient='index'\n",
    "        )\n",
    "        \n",
    "        return new_instance\n",
    "    \n",
    "    def get_trial_data(self, subject_id: str, trial_type: str) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Get trial data for a specific subject and trial type.\"\"\"\n",
    "        try:\n",
    "            trial_dict = self.processed_data[subject_id]['trial_data'][trial_type]\n",
    "            return trial_dict['data'] if trial_dict else None\n",
    "        except KeyError:\n",
    "            return None\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print summary statistics of the dataset.\"\"\"\n",
    "        print(f\"📊 Dataset Summary:\")\n",
    "        print(f\"Total subjects: {len(self.processed_data)}\")\n",
    "        \n",
    "        if self.metadata is not None:\n",
    "            # SIMPLIFIED AGE DISPLAY - always use age_months/12\n",
    "            ages = self.metadata['age_months'] / 12\n",
    "            print(f\"Age range: {ages.min():.1f} - {ages.max():.1f} years\")\n",
    "            print(f\"Mean age: {ages.mean():.1f} years\")\n",
    "        \n",
    "        # Trial type counts\n",
    "        trial_counts = defaultdict(int)\n",
    "        for subject_data in self.processed_data.values():\n",
    "            for trial_type in subject_data['trial_data'].keys():\n",
    "                trial_counts[trial_type] += 1\n",
    "        \n",
    "        print(f\"Trial type counts: {dict(trial_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77d5704-0c04-4d6e-990e-d46391979b3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 5. METRICS CALCULATOR\n",
    "# ==============================================================================\n",
    "\n",
    "class MetricsCalculator:\n",
    "    \"\"\"Updated to use config thresholds.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_manager: MotorLearningDataManager, motor_noise_strides: int = 10):\n",
    "        self.data_manager = data_manager\n",
    "        # KEY CHANGE: Get config from data_manager\n",
    "        self.config = data_manager.config\n",
    "        self.motor_noise_strides = self.config.MOTOR_NOISE_STRIDES\n",
    "    \n",
    "    def calculate_all_metrics(self) -> pd.DataFrame:\n",
    "        \"\"\"Calculate comprehensive performance metrics for all subjects.\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        print(f\"🧮 Calculating metrics for {len(self.data_manager.processed_data)} subjects...\")\n",
    "        \n",
    "        for i, (subject_id, data) in enumerate(self.data_manager.processed_data.items(), 1):\n",
    "            if i % 20 == 0:\n",
    "                print(f\"   Processed {i}/{len(self.data_manager.processed_data)} subjects...\")\n",
    "            \n",
    "            try:\n",
    "                subject_result = self._calculate_subject_metrics(subject_id, data)\n",
    "                if subject_result:\n",
    "                    results.append(subject_result)\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️ Error processing {subject_id}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not results:\n",
    "            print(\"❌ No valid metrics calculated!\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(results).infer_objects()\n",
    "        print(f\"✅ Successfully calculated metrics for {len(df)} subjects\")\n",
    "        \n",
    "        # Print age and column summary\n",
    "        if 'age' in df.columns:\n",
    "            ages = df['age'].dropna()\n",
    "            print(f\"📊 Age range: {ages.min():.1f} - {ages.max():.1f} years\")\n",
    "        \n",
    "        sr_cols = [col for col in df.columns if '_sr_' in col]\n",
    "        print(f\"🎯 Success rate columns created: {sr_cols}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _calculate_subject_metrics(self, subject_id: str, subject_data: Dict) -> Optional[Dict]:\n",
    "        \"\"\"Calculate metrics for a single subject with simplified age handling.\"\"\"\n",
    "        \n",
    "        # SIMPLIFIED: Only store age as age_months/12, call it 'age'\n",
    "        result = {\n",
    "            'ID': subject_id,\n",
    "            'age': subject_data['metadata'].get('age_months', np.nan) / 12,  # Single age field\n",
    "            'session_date': subject_data['metadata'].get('Session Date')\n",
    "        }\n",
    "        \n",
    "        # Process each trial type\n",
    "        for trial_type in ['vis1', 'invis', 'vis2']:\n",
    "            try:\n",
    "                trial_dict = subject_data['trial_data'].get(trial_type)\n",
    "                df = trial_dict['data'] if trial_dict else None\n",
    "                \n",
    "                if df is None or df.empty or 'Success' not in df.columns:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate metrics for both conditions\n",
    "                for condition in ['max', 'min']:\n",
    "                    period_data, indices = self._get_period_data(df, condition)\n",
    "                    if period_data is not None and not period_data.empty:\n",
    "                        metrics = self._calculate_period_metrics(period_data, trial_type, condition)\n",
    "                        result.update(metrics)\n",
    "                        result[f'{trial_type}_{condition}_const_indices'] = indices\n",
    "                \n",
    "                # Add trial metadata - ONLY if df is not None\n",
    "                if df is not None:\n",
    "                    result.update({\n",
    "                        f'{trial_type}_min_target_size': df['Target size'].min() if 'Target size' in df.columns else None,\n",
    "                        f'{trial_type}_max_constant': df['Constant'].max() if 'Constant' in df.columns else None,\n",
    "                        f'{trial_type}_min_constant': df['Constant'].min() if 'Constant' in df.columns else None\n",
    "                    })\n",
    "                    \n",
    "                    # Order information for invis trials\n",
    "                    if trial_type == 'invis':\n",
    "                        result.update(self._calculate_condition_order(df))\n",
    "                        \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        # Process preference trial\n",
    "        try:\n",
    "            pref_metrics = self._calculate_preference_metrics(subject_data['trial_data'].get('pref'))\n",
    "            result.update(pref_metrics)\n",
    "        except Exception as e:\n",
    "            result.update({'mot_noise': None, 'pref_asymmetry': None})\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _get_period_data(self, df: pd.DataFrame, condition: str, length: int = 20):\n",
    "        \"\"\"Extract data for specific condition period.\"\"\"\n",
    "        try:\n",
    "            if df is None or df.empty:\n",
    "                return None, None\n",
    "            \n",
    "            if 'Target size' not in df.columns or 'Constant' not in df.columns:\n",
    "                return None, None\n",
    "            \n",
    "            min_target = df['Target size'].min()\n",
    "            target_tolerance = 0.001\n",
    "            \n",
    "            min_target_periods = df[df['Target size'] <= min_target + target_tolerance]\n",
    "            if min_target_periods.empty:\n",
    "                return None, None\n",
    "            \n",
    "            const_value = (min_target_periods['Constant'].max() if condition == 'max'\n",
    "                          else min_target_periods['Constant'].min())\n",
    "            \n",
    "            period_data = min_target_periods[\n",
    "                np.isclose(min_target_periods['Constant'], const_value, rtol=1e-5)\n",
    "            ]\n",
    "            \n",
    "            if period_data.empty:\n",
    "                return None, None\n",
    "            \n",
    "            return period_data.tail(length), period_data.index\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None, None\n",
    "    \n",
    "    def _calculate_period_metrics(self, period_data: pd.DataFrame, trial_type: str, condition: str) -> Dict:\n",
    "        \"\"\"Calculate metrics for a specific period with naming.\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        try:\n",
    "            # CORRECTED: Use the format that analysis expects\n",
    "            # Success rate - THE KEY METRIC  \n",
    "            metrics[f'{trial_type}_sr_{condition}_const'] = period_data['Success'].mean()\n",
    "            \n",
    "            # Other metrics\n",
    "            if 'Sum of gains and steps' in period_data.columns:\n",
    "                sogs = period_data['Sum of gains and steps']\n",
    "                metrics[f'{trial_type}_sd_{condition}_const'] = sogs.std()\n",
    "                metrics[f'{trial_type}_msl_{condition}_const'] = sogs.mean()\n",
    "                metrics[f'{trial_type}_error_{condition}_const'] = (sogs - period_data['Constant']).mean()\n",
    "            \n",
    "            # Asymmetry\n",
    "            if all(col in period_data.columns for col in ['Right step length', 'Left step length']):\n",
    "                right_steps = period_data['Right step length']\n",
    "                left_steps = period_data['Left step length']\n",
    "                denominator = right_steps + left_steps\n",
    "                \n",
    "                valid_mask = denominator != 0\n",
    "                if valid_mask.any():\n",
    "                    asymmetry = ((right_steps - left_steps) / denominator).abs()[valid_mask].mean()\n",
    "                    metrics[f'{trial_type}_asymmetry_{condition}_const'] = asymmetry\n",
    "            \n",
    "            # Strides between successes\n",
    "            strides_between = self._calculate_strides_between_successes(period_data)\n",
    "            if strides_between is not None:\n",
    "                metrics[f'{trial_type}_strides_between_success_{condition}_const'] = strides_between\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _calculate_strides_between_successes(self, df: pd.DataFrame) -> Optional[float]:\n",
    "        \"\"\"Calculate average strides between successful trials.\"\"\"\n",
    "        try:\n",
    "            if df is None or 'Success' not in df.columns:\n",
    "                return None\n",
    "            \n",
    "            df = df.reset_index(drop=True)\n",
    "            success_positions = df.index[df['Success'] == 1].tolist()\n",
    "            \n",
    "            if len(success_positions) < 2:\n",
    "                return None\n",
    "            \n",
    "            return np.mean(np.diff(success_positions))\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def _calculate_condition_order(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Determine which condition came first for invis trials.\"\"\"\n",
    "        try:\n",
    "            all_max_indices = df.index[df['Constant'] == df['Constant'].max()].tolist()\n",
    "            all_min_indices = df.index[df['Constant'] == df['Constant'].min()].tolist()\n",
    "            \n",
    "            if all_max_indices and all_min_indices:\n",
    "                first_max = min(all_max_indices)\n",
    "                first_min = min(all_min_indices)\n",
    "                return {\n",
    "                    'invis_max_first': first_max < first_min,\n",
    "                    'invis_min_first': first_min < first_max\n",
    "                }\n",
    "            \n",
    "            return {'invis_max_first': False, 'invis_min_first': False}\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {'invis_max_first': False, 'invis_min_first': False}\n",
    "    \n",
    "    def _calculate_preference_metrics(self, pref_trial_dict: Optional[Dict]) -> Dict:\n",
    "        \"\"\"Calculate metrics from preference trial with configurable stride count.\"\"\"\n",
    "        metrics = {'mot_noise': None, 'pref_asymmetry': None}\n",
    "        \n",
    "        try:\n",
    "            if not pref_trial_dict or pref_trial_dict.get('data') is None:\n",
    "                return metrics\n",
    "            \n",
    "            pref_df = pref_trial_dict['data']\n",
    "            if pref_df is None or pref_df.empty:\n",
    "                return metrics\n",
    "            \n",
    "            # Check for required columns\n",
    "            if not all(col in pref_df.columns for col in ['Right step length', 'Left step length']):\n",
    "                return metrics\n",
    "            \n",
    "            # Get non-zero steps\n",
    "            right_steps = pref_df['Right step length']\n",
    "            left_steps = pref_df['Left step length']\n",
    "            \n",
    "            # Remove zeros and NaNs\n",
    "            right_clean = right_steps[(right_steps != 0) & (right_steps.notna())]\n",
    "            left_clean = left_steps[(left_steps != 0) & (left_steps.notna())]\n",
    "            \n",
    "            # Check if we have enough data\n",
    "            min_required = self.motor_noise_strides\n",
    "            if len(right_clean) < min_required or len(left_clean) < min_required:\n",
    "                print(f\"   ⚠️ Insufficient data for motor noise: need {min_required}, have R:{len(right_clean)}, L:{len(left_clean)}\")\n",
    "                return metrics\n",
    "            \n",
    "            # Calculate motor noise using configurable number of strides\n",
    "            final_right = right_clean.iloc[-1]\n",
    "            final_left = left_clean.iloc[-1]\n",
    "            \n",
    "            if final_right <= 0 or final_left <= 0:\n",
    "                return metrics\n",
    "            \n",
    "            # Normalize steps\n",
    "            norm_right = right_clean / final_right\n",
    "            norm_left = left_clean / final_left\n",
    "            \n",
    "            # Calculate sum of normalized steps\n",
    "            min_length = min(len(norm_right), len(norm_left))\n",
    "            if min_length < min_required:\n",
    "                return metrics\n",
    "            \n",
    "            sum_steps = norm_right.iloc[:min_length] + norm_left.iloc[:min_length]\n",
    "            \n",
    "            # Motor noise from last N points (configurable)\n",
    "            if len(sum_steps) >= self.motor_noise_strides:\n",
    "                noise = sum_steps.tail(self.motor_noise_strides).std()\n",
    "                if not pd.isna(noise) and noise > 0:\n",
    "                    metrics['mot_noise'] = noise\n",
    "            \n",
    "            # Calculate step length asymmetry using same number of strides\n",
    "            if len(right_clean) >= self.motor_noise_strides and len(left_clean) >= self.motor_noise_strides:\n",
    "                last_n_right = right_clean.tail(self.motor_noise_strides) / final_right\n",
    "                last_n_left = left_clean.tail(self.motor_noise_strides) / final_left\n",
    "                \n",
    "                if len(last_n_right) == len(last_n_left):\n",
    "                    denominator = last_n_right.values + last_n_left.values\n",
    "                    valid_mask = denominator != 0\n",
    "                    \n",
    "                    if valid_mask.any():\n",
    "                        asymmetry_vals = np.abs((last_n_right.values - last_n_left.values) / denominator)[valid_mask]\n",
    "                        if len(asymmetry_vals) > 0:\n",
    "                            metrics['pref_asymmetry'] = np.mean(asymmetry_vals)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ Error calculating preference metrics: {e}\")\n",
    "            pass\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c16add11-dcf4-42a5-bccc-c1373ab52afa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 6. STATISTICAL ANALYZER\n",
    "# ==============================================================================\n",
    "\n",
    "class StatisticalAnalyzer:\n",
    "    \"\"\"Updated to use config thresholds.\"\"\"\n",
    "    \n",
    "    def __init__(self, metrics_df: pd.DataFrame, config: Config = None):\n",
    "        self.metrics_df = metrics_df\n",
    "        \n",
    "        # KEY CHANGE: Accept config parameter\n",
    "        self.config = config if config else Config()\n",
    "        \n",
    "        # Apply motor noise filter using config\n",
    "        if 'mot_noise' in metrics_df.columns:\n",
    "            self.filtered_df = metrics_df[metrics_df['mot_noise'] <= self.config.MOTOR_NOISE_THRESHOLD]\n",
    "            print(f\"📊 Filtered to {len(self.filtered_df)}/{len(metrics_df)} subjects (motor noise ≤ {self.config.MOTOR_NOISE_THRESHOLD})\")\n",
    "        else:\n",
    "            self.filtered_df = metrics_df\n",
    "    \n",
    "    def run_regression_analysis(self, trial_type: str = 'invis', condition: str = 'max',\n",
    "                               predictors: List[str] = None, model_type: str = 'linear') -> Dict:\n",
    "        \"\"\"Run regression analysis withtarget column naming.\"\"\"\n",
    "        \n",
    "        if predictors is None:\n",
    "            predictors = ['age', 'mot_noise', 'pref_asymmetry']\n",
    "        \n",
    "        # Filter available predictors\n",
    "        available_predictors = [p for p in predictors if p in self.filtered_df.columns]\n",
    "        \n",
    "        # CORRECTED: Use the exact column format that exists\n",
    "        target_col = f'{trial_type}_sr_{condition}_const'\n",
    "        \n",
    "        if target_col not in self.filtered_df.columns:\n",
    "            available_cols = [col for col in self.filtered_df.columns if '_sr_' in col]\n",
    "            raise ValueError(f\"Target column {target_col} not found. Available: {available_cols}\")\n",
    "        \n",
    "        # Prepare data\n",
    "        valid_data = self.filtered_df[available_predictors + [target_col]].dropna()\n",
    "        \n",
    "        if len(valid_data) < 10:\n",
    "            raise ValueError(f\"Insufficient data: only {len(valid_data)} valid samples\")\n",
    "        \n",
    "        X = valid_data[available_predictors]\n",
    "        y = valid_data[target_col]\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Create model\n",
    "        if model_type == 'linear':\n",
    "            model = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', LinearRegression())\n",
    "            ])\n",
    "        elif model_type == 'random_forest':\n",
    "            model = RandomForestRegressor(random_state=42)\n",
    "        else:\n",
    "            raise ValueError(\"model_type must be 'linear' or 'random_forest'\")\n",
    "        \n",
    "        # Fit and predict\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "        # Feature importance\n",
    "        if model_type == 'random_forest':\n",
    "            importances = dict(zip(available_predictors, model.feature_importances_))\n",
    "        else:\n",
    "            importances = dict(zip(available_predictors, \n",
    "                                 np.abs(model.named_steps['regressor'].coef_)))\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'y_pred': y_pred,\n",
    "            'metrics': {\n",
    "                'r2': r2,\n",
    "                'rmse': rmse,\n",
    "                'n_samples': len(valid_data),\n",
    "                'trial_type': trial_type,\n",
    "                'condition': condition,\n",
    "                'predictors': available_predictors\n",
    "            },\n",
    "            'feature_importances': importances\n",
    "        }\n",
    "    \n",
    "    def run_classification_analysis(self, trial_type: str = 'invis', condition: str = 'max',\n",
    "                                   threshold: float = 0.68, model_type: str = 'logistic') -> Dict:\n",
    "        \"\"\"Run binary classification withtarget column naming.\"\"\"\n",
    "        \n",
    "        predictors = ['age', 'mot_noise']\n",
    "        available_predictors = [p for p in predictors if p in self.filtered_df.columns]\n",
    "        \n",
    "        # CORRECTED: Use the exact column format that exists\n",
    "        target_col = f'{trial_type}_sr_{condition}_const'\n",
    "        \n",
    "        if target_col not in self.filtered_df.columns:\n",
    "            available_cols = [col for col in self.filtered_df.columns if '_sr_' in col]\n",
    "            raise ValueError(f\"Target column {target_col} not found. Available: {available_cols}\")\n",
    "        \n",
    "        # Prepare data\n",
    "        valid_data = self.filtered_df[available_predictors + [target_col]].dropna()\n",
    "        \n",
    "        if len(valid_data) < 10:\n",
    "            raise ValueError(f\"Insufficient data: only {len(valid_data)} valid samples\")\n",
    "        \n",
    "        # Create binary target\n",
    "        y = (valid_data[target_col] >= threshold).astype(int)\n",
    "        X = valid_data[available_predictors]\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Create model\n",
    "        if model_type == 'logistic':\n",
    "            model = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('classifier', LogisticRegression(random_state=42))\n",
    "            ])\n",
    "        elif model_type == 'random_forest':\n",
    "            model = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('classifier', RandomForestClassifier(random_state=42))\n",
    "            ])\n",
    "        else:\n",
    "            raise ValueError(\"model_type must be 'logistic' or 'random_forest'\")\n",
    "        \n",
    "        # Fit and predict\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_proba),\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "            'n_samples': len(valid_data),\n",
    "            'threshold': threshold,\n",
    "            'trial_type': trial_type,\n",
    "            'condition': condition,\n",
    "            'predictors': available_predictors\n",
    "        }\n",
    "        \n",
    "        # Feature importance\n",
    "        if model_type == 'random_forest':\n",
    "            importances = dict(zip(available_predictors, \n",
    "                                 model.named_steps['classifier'].feature_importances_))\n",
    "        else:\n",
    "            importances = dict(zip(available_predictors, \n",
    "                                 model.named_steps['classifier'].coef_[0]))\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'y_pred': y_pred,\n",
    "            'y_proba': y_proba,\n",
    "            'metrics': metrics,\n",
    "            'feature_importances': importances\n",
    "        }\n",
    "    \n",
    "    def run_mixed_effects_analysis(self, trial_types: Union[str, List[str]] = 'all') -> object:\n",
    "        \"\"\"Run mixed-effects analysis withcolumn naming.\"\"\"\n",
    "        \n",
    "        # Prepare long-format data\n",
    "        long_rows = []\n",
    "        \n",
    "        if trial_types == 'all':\n",
    "            trials_to_include = ['vis1', 'invis', 'vis2']\n",
    "        elif isinstance(trial_types, str):\n",
    "            trials_to_include = [trial_types]\n",
    "        else:\n",
    "            trials_to_include = trial_types\n",
    "        \n",
    "        for trial in trials_to_include:\n",
    "            for condition in ['max_const', 'min_const']:\n",
    "                # CORRECTED: Use the exact column format\n",
    "                sr_col = f\"{trial}_sr_{condition}\"\n",
    "                if sr_col in self.filtered_df.columns:\n",
    "                    sub_df = self.filtered_df[['ID', sr_col, 'mot_noise', 'age']].copy()\n",
    "                    sub_df = sub_df.rename(columns={sr_col: 'success_rate'})\n",
    "                    sub_df['trial_type'] = trial\n",
    "                    sub_df['condition'] = condition\n",
    "                    long_rows.append(sub_df)\n",
    "        \n",
    "        if not long_rows:\n",
    "            raise ValueError(\"No success rate data available\")\n",
    "        \n",
    "        df_long = pd.concat(long_rows, ignore_index=True)\n",
    "        df_long.dropna(subset=['success_rate', 'mot_noise', 'age'], inplace=True)\n",
    "        \n",
    "        # Fit model\n",
    "        if len(trials_to_include) == 1:\n",
    "            formula = 'success_rate ~ C(condition) + mot_noise + age'\n",
    "        else:\n",
    "            formula = 'success_rate ~ C(trial_type) + C(condition) + mot_noise + age'\n",
    "        \n",
    "        model = smf.ols(formula, data=df_long).fit()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b65ce6-705a-4a3a-8bf2-1dd1aaeacfea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 8. ANALYSIS PIPELINE\n",
    "# ==============================================================================\n",
    "# ORIGINAL ANALYSIS CLASS (RESTORED)\n",
    "# ==================================\n",
    "# This version uses the fixed StandaloneEnhancedVisualizer\n",
    "\n",
    "class MotorLearningAnalysis:\n",
    "    \"\"\"Updated to use centralized config and new visualizer.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_manager, metrics_df: pd.DataFrame):\n",
    "        self.data_manager = data_manager\n",
    "        self.metrics_df = metrics_df\n",
    "        \n",
    "        # KEY CHANGE: Get config from data_manager\n",
    "        self.config = data_manager.config\n",
    "        \n",
    "        # KEY CHANGE: Pass config to analyzer\n",
    "        self.analyzer = StatisticalAnalyzer(metrics_df, self.config)\n",
    "        \n",
    "        # KEY CHANGE: Use StandaloneEnhancedVisualizer with config\n",
    "        self.visualizer = StandaloneEnhancedVisualizer(self)\n",
    "    \n",
    "    def run_comprehensive_analysis(self, save_all: bool = True) -> Dict:\n",
    "        \"\"\"Updated to use config for saving.\"\"\"\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        print(\"🔬 Running Comprehensive Motor Learning Analysis...\")\n",
    "        print(f\"📁 Outputs will be saved to: {self.config.BASE_OUTPUT_DIR}\")\n",
    "        \n",
    "        # Print age summary (unchanged)\n",
    "        if 'age' in self.metrics_df.columns:\n",
    "            ages = self.metrics_df['age'].dropna()\n",
    "            print(f\"📊 Age range: {ages.min():.1f} - {ages.max():.1f} years (n={len(ages)})\")\n",
    "        \n",
    "        # 1. Regression Analysis (unchanged logic, but could use config thresholds)\n",
    "        print(\"📊 Running regression analysis...\")\n",
    "        try:\n",
    "            regression_results = self.analyzer.run_regression_analysis()\n",
    "            results['regression'] = regression_results\n",
    "            print(f\"✅ Regression R² = {regression_results['metrics']['r2']:.3f}\")\n",
    "            \n",
    "            for feature, importance in regression_results['feature_importances'].items():\n",
    "                print(f\"   {feature}: {importance:.4f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Regression analysis failed: {e}\")\n",
    "        \n",
    "        # 2. Classification Analysis (unchanged)\n",
    "        print(\"🎯 Running classification analysis...\")\n",
    "        try:\n",
    "            classification_results = self.analyzer.run_classification_analysis()\n",
    "            results['classification'] = classification_results\n",
    "            print(f\"✅ Classification AUC = {classification_results['metrics']['roc_auc']:.3f}\")\n",
    "            print(f\"   Accuracy = {classification_results['metrics']['accuracy']:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Classification analysis failed: {e}\")\n",
    "        \n",
    "        # 3. Mixed Effects Analysis (unchanged)\n",
    "        print(\"📈 Running mixed-effects analysis...\")\n",
    "        try:\n",
    "            mixed_model = self.analyzer.run_mixed_effects_analysis()\n",
    "            results['mixed_effects'] = mixed_model\n",
    "            print(f\"✅ Mixed-effects R² = {mixed_model.rsquared:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Mixed-effects analysis failed: {e}\")\n",
    "        \n",
    "        # 4. Enhanced Visualizations - KEY CHANGE: Uses config-managed paths\n",
    "        print(\"📊 Generating enhanced visualizations...\")\n",
    "        try:\n",
    "            # The visualizer now automatically saves to config-managed directories\n",
    "            self.visualizer.plot_population_analyses(save=save_all)\n",
    "            print(\"✅ Enhanced visualizations complete\")\n",
    "            print(f\"📁 Plots saved to: {self.config.POPULATION_PLOTS_DIR}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Visualization failed: {e}\")\n",
    "        \n",
    "        print(\"🎉 Comprehensive analysis complete!\")\n",
    "        print(f\"📁 All outputs in: {self.config.BASE_OUTPUT_DIR}\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0037914-1cf4-47e2-8b65-fd9fdb9eb1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎨 CONSOLIDATED ENHANCED VISUALIZER DEMONSTRATION\n",
      "============================================================\n",
      "\n",
      "🔧 Step 1: Create your analysis instance (existing code)\n",
      "# analysis = MotorLearningAnalysis(data_manager, metrics_df)\n",
      "\n",
      "🎨 Step 2: Create consolidated enhanced visualizer\n",
      "# enhanced_viz = StandaloneEnhancedVisualizer(analysis)\n",
      "\n",
      "📊 Step 3: Generate ALL plots in one call\n",
      "# results = enhanced_viz.generate_all_enhanced_plots(include_individual_plots=True)\n",
      "\n",
      "🎯 OR generate specific plot categories:\n",
      "# enhanced_viz.generate_enhanced_population_plots()\n",
      "# enhanced_viz.generate_statistical_plots()\n",
      "# enhanced_viz.generate_summary_dashboard()\n",
      "\n",
      "🚀 OR use the streamlined pipeline (uses consolidated visualizer internally)\n",
      "# pipeline = StreamlinedMotorLearningPipeline(analysis)\n",
      "# results = pipeline.run_complete_analysis(include_individual_plots=True)\n",
      "\n",
      "✅ ALL plotting methods are now consolidated in StandaloneEnhancedVisualizer!\n",
      "📁 Organized output directories with enhanced plots\n",
      "🎨 Motor noise coloring, age effects, trial comparisons, and more\n",
      "📊 Statistical analysis plots and comprehensive dashboard\n",
      "🎯 Optional individual stride change plots for detailed analysis\n"
     ]
    }
   ],
   "source": [
    "# ENHANCED STANDALONE VISUALIZER WITH CONSOLIDATED PLOTTING METHODS\n",
    "# ==============================================================================\n",
    "# This consolidates all plotting methods from StreamlinedMotorLearningPipeline\n",
    "# into the StandaloneEnhancedVisualizer class for better organization\n",
    "\n",
    "\n",
    "\n",
    "class StandaloneEnhancedVisualizer:\n",
    "    \"\"\"\n",
    "    Enhanced visualizer that consolidates ALL plotting functionality.\n",
    "    \n",
    "    Key improvements:\n",
    "    - All plotting methods moved from StreamlinedMotorLearningPipeline\n",
    "    - Enhanced population statistics with motor noise coloring\n",
    "    - Age vs success rates by trial/condition\n",
    "    - Age vs stride variability by trial/condition  \n",
    "    - Mean stride length vs success rate by trial/condition\n",
    "    - Motor noise vs success rates analysis\n",
    "    - Age vs mean stride length and error analysis\n",
    "    - Statistical analysis plots\n",
    "    - Summary dashboard generation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, analysis_instance, config: 'Config' = None):\n",
    "        \"\"\"\n",
    "        Initialize with your existing analysis instance.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        analysis_instance : Your existing MotorLearningAnalysis object\n",
    "            Should have .data_manager, .metrics_df attributes\n",
    "        config : Config object\n",
    "            Configuration settings\n",
    "        \"\"\"\n",
    "        self.analysis = analysis_instance\n",
    "        self.metrics_df = analysis_instance.metrics_df\n",
    "        self.data_manager = analysis_instance.data_manager\n",
    "        \n",
    "        # Use provided config or get from data_manager or create default\n",
    "        if config:\n",
    "            self.config = config\n",
    "        elif hasattr(self.data_manager, 'config'):\n",
    "            self.config = self.data_manager.config\n",
    "        else:\n",
    "            # Create minimal config if none available\n",
    "            self.config = self._create_minimal_config()\n",
    "        \n",
    "        # Set up directory attributes properly\n",
    "        self.individual_plots_dir = self.config.INDIVIDUAL_PLOTS_DIR\n",
    "        self.population_plots_dir = self.config.POPULATION_PLOTS_DIR\n",
    "        self.statistical_plots_dir = self.config.STATISTICAL_PLOTS_DIR\n",
    "        \n",
    "        # Apply motor noise filter\n",
    "        if 'mot_noise' in self.metrics_df.columns:\n",
    "            motor_noise_threshold = getattr(self.config, 'MOTOR_NOISE_THRESHOLD', 0.3)\n",
    "            self.filtered_df = self.metrics_df[self.metrics_df['mot_noise'] <= motor_noise_threshold]\n",
    "            print(f\"📊 Using {len(self.filtered_df)}/{len(self.metrics_df)} subjects (motor noise ≤ {motor_noise_threshold})\")\n",
    "        else:\n",
    "            self.filtered_df = self.metrics_df\n",
    "            print(f\"📊 Using all {len(self.filtered_df)} subjects\")\n",
    "        \n",
    "        # Set colors\n",
    "        self.colors = {\n",
    "            'primary': '#667eea',\n",
    "            'secondary': '#764ba2',\n",
    "            'success': '#28a745',\n",
    "            'warning': '#ffc107',\n",
    "            'danger': '#dc3545',\n",
    "            'vis1': '#1f77b4',\n",
    "            'invis': '#ff7f0e', \n",
    "            'vis2': '#2ca02c'\n",
    "        }\n",
    "        \n",
    "        print(f\"✅ Enhanced visualizer initialized with consolidated plotting methods\")\n",
    "        print(f\"📁 Individual plots: {self.individual_plots_dir}\")\n",
    "        print(f\"📁 Population plots: {self.population_plots_dir}\")\n",
    "        print(f\"📁 Statistical plots: {self.statistical_plots_dir}\")\n",
    "\n",
    "    def _create_minimal_config(self):\n",
    "        \"\"\"Create minimal config if none provided.\"\"\"\n",
    "        class MinimalConfig:\n",
    "            def __init__(self):\n",
    "                base_dir = Path('motor_learning_output')\n",
    "                base_dir.mkdir(exist_ok=True)\n",
    "                \n",
    "                self.BASE_OUTPUT_DIR = base_dir\n",
    "                self.INDIVIDUAL_PLOTS_DIR = base_dir / 'figures' / 'individual_plots'\n",
    "                self.POPULATION_PLOTS_DIR = base_dir / 'figures' / 'population_plots'\n",
    "                self.STATISTICAL_PLOTS_DIR = base_dir / 'figures' / 'statistical_plots'\n",
    "                \n",
    "                for dir_path in [self.INDIVIDUAL_PLOTS_DIR, self.POPULATION_PLOTS_DIR, self.STATISTICAL_PLOTS_DIR]:\n",
    "                    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                self.MOTOR_NOISE_THRESHOLD = 0.3\n",
    "                self.SUCCESS_RATE_THRESHOLD = 0.68\n",
    "                self.FIGURE_DPI = 300\n",
    "        \n",
    "        return MinimalConfig()\n",
    "\n",
    "    # ==========================================================================\n",
    "    # COMPREHENSIVE PLOTTING METHODS\n",
    "    # ==========================================================================\n",
    "\n",
    "    def generate_all_enhanced_plots(self, include_individual_plots: bool = False, \n",
    "                                  max_individual_subjects: int = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate ALL enhanced visualizations in one call.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        include_individual_plots : bool, default False\n",
    "            Whether to generate individual participant plots (time-consuming)\n",
    "        max_individual_subjects : int, optional\n",
    "            Maximum number of subjects for individual plots (useful for testing)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Dict : Summary of generated plots\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"🚀 Starting comprehensive enhanced plotting analysis...\")\n",
    "        print(f\"⏰ Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"🎯 Individual plots: {'Enabled' if include_individual_plots else 'Disabled'}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        results = {\n",
    "            'timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "            'individual_plots': 0,\n",
    "            'population_plots': 0,\n",
    "            'statistical_plots': 0,\n",
    "            'generated_files': []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # 1. Individual stride change plots (OPTIONAL)\n",
    "            if include_individual_plots:\n",
    "                print(\"\\n🎯 INDIVIDUAL STRIDE CHANGE PLOTS\")\n",
    "                print(\"-\" * 50)\n",
    "                individual_result = self.plot_all_individual_stride_changes(\n",
    "                    trial_types=['vis1', 'invis', 'vis2'],\n",
    "                    subject_ids=None,\n",
    "                    save_summary=True,\n",
    "                    max_subjects=max_individual_subjects\n",
    "                )\n",
    "                results['individual_plots'] = len(individual_result) if individual_result else 0\n",
    "            else:\n",
    "                print(\"\\n⏭️ Skipping individual plots (set include_individual_plots=True to enable)\")\n",
    "            \n",
    "            # 2. Enhanced population-level plots\n",
    "            print(\"\\n👥 ENHANCED POPULATION-LEVEL ANALYSIS PLOTS\")\n",
    "            print(\"-\" * 50)\n",
    "            population_result = self.generate_enhanced_population_plots()\n",
    "            results['population_plots'] = population_result.get('n_plots', 0)\n",
    "            results['generated_files'].extend(population_result.get('files', []))\n",
    "            \n",
    "            # 3. Statistical analysis plots\n",
    "            print(\"\\n📊 STATISTICAL ANALYSIS PLOTS\")\n",
    "            print(\"-\" * 50)\n",
    "            statistical_result = self.generate_statistical_plots()\n",
    "            results['statistical_plots'] = statistical_result.get('n_plots', 0)\n",
    "            results['generated_files'].extend(statistical_result.get('files', []))\n",
    "            \n",
    "            # 4. Summary dashboard\n",
    "            print(\"\\n📋 SUMMARY DASHBOARD\")\n",
    "            print(\"-\" * 50)\n",
    "            dashboard_result = self.generate_summary_dashboard()\n",
    "            if dashboard_result.get('success'):\n",
    "                results['generated_files'].append(dashboard_result['file'])\n",
    "            \n",
    "            # Final summary\n",
    "            total_plots = results['individual_plots'] + results['population_plots'] + results['statistical_plots']\n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "            print(\"🎉 ENHANCED PLOTTING COMPLETED SUCCESSFULLY!\")\n",
    "            print(\"=\" * 80)\n",
    "            print(f\"⏰ Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            print(f\"📊 Total plots generated: {total_plots}\")\n",
    "            print(f\"   • Individual plots: {results['individual_plots']}\")\n",
    "            print(f\"   • Population plots: {results['population_plots']}\")\n",
    "            print(f\"   • Statistical plots: {results['statistical_plots']}\")\n",
    "            print(f\"📁 Files saved to: {self.config.BASE_OUTPUT_DIR}\")\n",
    "            \n",
    "            if not include_individual_plots:\n",
    "                print(\"💡 To generate individual plots, use: generate_all_enhanced_plots(include_individual_plots=True)\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Enhanced plotting failed: {e}\")\n",
    "            results['error'] = str(e)\n",
    "            raise\n",
    "\n",
    "    def generate_enhanced_population_plots(self) -> Dict:\n",
    "        \"\"\"Generate ALL enhanced population-level analysis plots.\"\"\"\n",
    "        \n",
    "        plot_count = 0\n",
    "        generated_files = []\n",
    "        df = self.filtered_df\n",
    "        \n",
    "        try:\n",
    "            print(\"📊 Generating enhanced population-level analysis plots...\")\n",
    "            \n",
    "            # 1. ENHANCED: Age vs Success Rates by trial/condition with motor noise coloring\n",
    "            print(\"   🎯 Age vs Success Rates (Enhanced by trial/condition)...\")\n",
    "            self._plot_age_vs_success_rates_enhanced(df)\n",
    "            plot_count += 1\n",
    "            generated_files.append('age_vs_success_rates_enhanced.png')\n",
    "            \n",
    "            # 2. ENHANCED: Age vs Stride Variability by trial/condition with motor noise coloring\n",
    "            print(\"   📏 Age vs Stride Variability (Enhanced by trial/condition)...\")\n",
    "            self._plot_age_vs_stride_variability_enhanced(df)\n",
    "            plot_count += 1\n",
    "            generated_files.append('age_vs_stride_variability_enhanced.png')\n",
    "            \n",
    "            # 3. Mean Stride Length vs Success Rate by trial/condition with motor noise coloring\n",
    "            print(\"   📊 Mean Stride Length vs Success Rate (by trial/condition)...\")\n",
    "            self._plot_msl_vs_sr_enhanced(df)\n",
    "            plot_count += 1\n",
    "            generated_files.append('mean_stride_length_vs_success_rate.png')\n",
    "            \n",
    "            # 4. Age vs Mean Stride Length by trial/condition with motor noise coloring\n",
    "            print(\"   📏 Age vs Mean Stride Length (Enhanced by trial/condition)...\")\n",
    "            self._plot_age_vs_mean_stride_length_enhanced(df)\n",
    "            plot_count += 1\n",
    "            generated_files.append('age_vs_mean_stride_length_enhanced.png')\n",
    "            \n",
    "            # 5. Age vs Mean Error by trial/condition with motor noise coloring\n",
    "            print(\"   🎯 Age vs Mean Error (Enhanced by trial/condition)...\")\n",
    "            self._plot_age_vs_mean_error_enhanced(df)\n",
    "            plot_count += 1\n",
    "            generated_files.append('age_vs_mean_error_enhanced.png')\n",
    "            \n",
    "            # 6. NEW: Mean Error vs Success Rate by trial/condition with motor noise coloring\n",
    "            print(\"   📊 Mean Error vs Success Rate (Enhanced by trial/condition)...\")\n",
    "            self._plot_mean_error_vs_success_rate_enhanced(df)\n",
    "            plot_count += 1\n",
    "            generated_files.append('mean_error_vs_success_rate_enhanced.png')\n",
    "            \n",
    "            # 7. Motor Noise vs Success Rate by trial/condition with age coloring\n",
    "            print(\"   🧠 Motor Noise vs Success Rate (by trial/condition)...\")\n",
    "            self._plot_motor_noise_vs_success_rates_enhanced(df)\n",
    "            plot_count += 1\n",
    "            generated_files.append('motor_noise_vs_success_rates_enhanced.png')\n",
    "            \n",
    "            # 8. Age vs Motor Noise\n",
    "            if 'age' in df.columns and 'mot_noise' in df.columns:\n",
    "                print(\"   👥 Age vs Motor Noise...\")\n",
    "                self._plot_age_vs_motor_noise(df)\n",
    "                plot_count += 1\n",
    "                generated_files.append('age_vs_motor_noise.png')\n",
    "            \n",
    "            # 9. Correlation Matrix\n",
    "            print(\"   🔗 Correlation Matrix...\")\n",
    "            self._plot_correlation_matrix(df)\n",
    "            plot_count += 1\n",
    "            generated_files.append('correlation_matrix.png')\n",
    "            \n",
    "            # 10. Success Rate Overview\n",
    "            sr_cols = [col for col in df.columns if '_sr_' in col and '_const' in col]\n",
    "            if sr_cols:\n",
    "                print(\"   📊 Success Rate Overview...\")\n",
    "                self._plot_success_rate_overview(df, sr_cols)\n",
    "                plot_count += 1\n",
    "                generated_files.append('success_rate_overview.png')\n",
    "            \n",
    "            print(f\"   ✅ Generated {plot_count} enhanced population-level plots\")\n",
    "            \n",
    "            return {\n",
    "                'n_plots': plot_count,\n",
    "                'files': generated_files,\n",
    "                'output_dir': str(self.population_plots_dir),\n",
    "                'enhanced': True\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ Enhanced population plots failed: {e}\")\n",
    "            return {'n_plots': 0, 'error': str(e), 'enhanced': False}\n",
    "\n",
    "    def generate_statistical_plots(self) -> Dict:\n",
    "        \"\"\"Generate statistical analysis visualization plots.\"\"\"\n",
    "        \n",
    "        plot_count = 0\n",
    "        generated_files = []\n",
    "        \n",
    "        try:\n",
    "            print(\"📊 Generating statistical analysis plots...\")\n",
    "            \n",
    "            # 1. Feature importance analysis (if available)\n",
    "            if hasattr(self.analysis, 'analyzer'):\n",
    "                print(\"   📈 Feature Importance Analysis...\")\n",
    "                self._plot_feature_importance_analysis()\n",
    "                plot_count += 1\n",
    "                generated_files.append('feature_importance_analysis.png')\n",
    "            \n",
    "            # 2. Age effects summary\n",
    "            print(\"   👥 Age Effects Summary...\")\n",
    "            self._plot_age_effects_summary()\n",
    "            plot_count += 1\n",
    "            generated_files.append('age_effects_summary.png')\n",
    "            \n",
    "            # 3. Trial comparisons\n",
    "            print(\"   🎮 Trial Type Comparisons...\")\n",
    "            self._plot_trial_comparisons()\n",
    "            plot_count += 1\n",
    "            generated_files.append('trial_comparisons.png')\n",
    "            \n",
    "            print(f\"   ✅ Generated {plot_count} statistical analysis plots\")\n",
    "            \n",
    "            return {\n",
    "                'n_plots': plot_count,\n",
    "                'files': generated_files,\n",
    "                'output_dir': str(self.statistical_plots_dir)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ Statistical plots failed: {e}\")\n",
    "            return {'n_plots': 0, 'error': str(e)}\n",
    "\n",
    "    # ==========================================================================\n",
    "    # ENHANCED POPULATION PLOTTING METHODS\n",
    "    # ==========================================================================\n",
    "\n",
    "    def _plot_age_vs_success_rates_enhanced(self, df: pd.DataFrame):\n",
    "        \"\"\"Enhanced age vs success rates by trial/condition with motor noise coloring.\"\"\"\n",
    "        \n",
    "        sr_columns = [col for col in df.columns if '_sr_' in col and '_const' in col]\n",
    "        if not sr_columns:\n",
    "            print(\"   ⚠️ No success rate columns found\")\n",
    "            return\n",
    "        \n",
    "        trials = ['vis1', 'invis', 'vis2']\n",
    "        conditions = ['max', 'min']\n",
    "        has_motor_noise = 'mot_noise' in df.columns\n",
    "        \n",
    "        fig, axes = plt.subplots(len(trials), len(conditions), figsize=(12, 4*len(trials)))\n",
    "        if len(trials) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, trial in enumerate(trials):\n",
    "            for j, condition in enumerate(conditions):\n",
    "                ax = axes[i, j]\n",
    "                col = f'{trial}_sr_{condition}_const'\n",
    "                \n",
    "                if col in df.columns:\n",
    "                    cols_to_use = ['age', col] + (['mot_noise'] if has_motor_noise else [])\n",
    "                    valid_data = df[cols_to_use].dropna()\n",
    "                    \n",
    "                    if not valid_data.empty:\n",
    "                        if has_motor_noise:\n",
    "                            scatter = ax.scatter(valid_data['age'], valid_data[col], \n",
    "                                               c=valid_data['mot_noise'], cmap='plasma', \n",
    "                                               alpha=0.7, s=60, edgecolors='white', linewidths=0.5)\n",
    "                            if i == 0 and j == len(conditions) - 1:\n",
    "                                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                                cbar.set_label('Motor Noise', rotation=270, labelpad=15)\n",
    "                        else:\n",
    "                            ax.scatter(valid_data['age'], valid_data[col], alpha=0.7, s=60)\n",
    "                        \n",
    "                        # Add trend line and correlation\n",
    "                        self._add_trendline(ax, valid_data['age'], valid_data[col])\n",
    "                        \n",
    "                        ax.set_xlabel('Age (years)')\n",
    "                        ax.set_ylabel('Success Rate')\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                        ax.set_ylim(-0.05, 1.05)\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, 'No Data', ha='center', va='center',\n",
    "                               transform=ax.transAxes, fontsize=12)\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, 'Column Not Found', ha='center', va='center',\n",
    "                           transform=ax.transAxes, fontsize=12)\n",
    "                    ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "        \n",
    "        plt.suptitle('Age vs Success Rates by Trial/Condition (Colored by Motor Noise)' if has_motor_noise \n",
    "                     else 'Age vs Success Rates by Trial/Condition', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.population_plots_dir / 'age_vs_success_rates_enhanced.png', \n",
    "                   dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_age_vs_stride_variability_enhanced(self, df: pd.DataFrame):\n",
    "        \"\"\"Enhanced age vs stride variability by trial/condition with motor noise coloring.\"\"\"\n",
    "        \n",
    "        sd_columns = [col for col in df.columns if '_sd_' in col and '_const' in col]\n",
    "        if not sd_columns:\n",
    "            print(\"   ⚠️ No stride variability columns found\")\n",
    "            return\n",
    "        \n",
    "        trials = ['vis1', 'invis', 'vis2']\n",
    "        conditions = ['max', 'min']\n",
    "        has_motor_noise = 'mot_noise' in df.columns\n",
    "        \n",
    "        fig, axes = plt.subplots(len(trials), len(conditions), figsize=(12, 4*len(trials)))\n",
    "        if len(trials) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, trial in enumerate(trials):\n",
    "            for j, condition in enumerate(conditions):\n",
    "                ax = axes[i, j]\n",
    "                col = f'{trial}_sd_{condition}_const'\n",
    "                \n",
    "                if col in df.columns:\n",
    "                    cols_to_use = ['age', col] + (['mot_noise'] if has_motor_noise else [])\n",
    "                    valid_data = df[cols_to_use].dropna()\n",
    "                    \n",
    "                    if not valid_data.empty:\n",
    "                        if has_motor_noise:\n",
    "                            scatter = ax.scatter(valid_data['age'], valid_data[col], \n",
    "                                               c=valid_data['mot_noise'], cmap='viridis', \n",
    "                                               alpha=0.7, s=60, edgecolors='white', linewidths=0.5)\n",
    "                            if i == 0 and j == len(conditions) - 1:\n",
    "                                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                                cbar.set_label('Motor Noise', rotation=270, labelpad=15)\n",
    "                        else:\n",
    "                            ax.scatter(valid_data['age'], valid_data[col], alpha=0.7, s=60)\n",
    "                        \n",
    "                        # Add trend line and correlation\n",
    "                        self._add_trendline(ax, valid_data['age'], valid_data[col])\n",
    "                        \n",
    "                        ax.set_xlabel('Age (years)')\n",
    "                        ax.set_ylabel('Stride Length SD')\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, 'No Data', ha='center', va='center',\n",
    "                               transform=ax.transAxes, fontsize=12)\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, 'Column Not Found', ha='center', va='center',\n",
    "                           transform=ax.transAxes, fontsize=12)\n",
    "                    ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "        \n",
    "        plt.suptitle('Age vs Stride Variability by Trial/Condition (Colored by Motor Noise)' if has_motor_noise \n",
    "                     else 'Age vs Stride Variability by Trial/Condition', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.population_plots_dir / 'age_vs_stride_variability_enhanced.png', \n",
    "                   dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_msl_vs_sr_enhanced(self, df: pd.DataFrame):\n",
    "        \"\"\"Mean stride length vs success rate by trial/condition with motor noise coloring.\"\"\"\n",
    "        \n",
    "        msl_columns = [col for col in df.columns if '_msl_' in col and '_const' in col]\n",
    "        sr_columns = [col for col in df.columns if '_sr_' in col and '_const' in col]\n",
    "        \n",
    "        if not msl_columns or not sr_columns:\n",
    "            print(\"   ⚠️ Missing mean stride length or success rate columns\")\n",
    "            return\n",
    "        \n",
    "        trials = ['vis1', 'invis', 'vis2']\n",
    "        conditions = ['max', 'min']\n",
    "        has_motor_noise = 'mot_noise' in df.columns\n",
    "        \n",
    "        fig, axes = plt.subplots(len(trials), len(conditions), figsize=(12, 4*len(trials)))\n",
    "        if len(trials) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, trial in enumerate(trials):\n",
    "            for j, condition in enumerate(conditions):\n",
    "                ax = axes[i, j]\n",
    "                msl_col = f'{trial}_msl_{condition}_const'\n",
    "                sr_col = f'{trial}_sr_{condition}_const'\n",
    "                \n",
    "                if msl_col in df.columns and sr_col in df.columns:\n",
    "                    cols_to_use = [msl_col, sr_col] + (['mot_noise'] if has_motor_noise else [])\n",
    "                    valid_data = df[cols_to_use].dropna()\n",
    "                    \n",
    "                    if not valid_data.empty:\n",
    "                        if has_motor_noise:\n",
    "                            scatter = ax.scatter(valid_data[msl_col], valid_data[sr_col], \n",
    "                                               c=valid_data['mot_noise'], cmap='coolwarm', \n",
    "                                               alpha=0.7, s=60, edgecolors='white', linewidths=0.5)\n",
    "                            if i == 0 and j == len(conditions) - 1:\n",
    "                                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                                cbar.set_label('Motor Noise', rotation=270, labelpad=15)\n",
    "                        else:\n",
    "                            ax.scatter(valid_data[msl_col], valid_data[sr_col], alpha=0.7, s=60)\n",
    "                        \n",
    "                        # Add trend line and correlation\n",
    "                        self._add_trendline(ax, valid_data[msl_col], valid_data[sr_col])\n",
    "                        \n",
    "                        ax.set_xlabel('Mean Stride Length')\n",
    "                        ax.set_ylabel('Success Rate')\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                        ax.set_ylim(-0.05, 1.05)\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, 'No Data', ha='center', va='center',\n",
    "                               transform=ax.transAxes, fontsize=12)\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, 'Columns Not Found', ha='center', va='center',\n",
    "                           transform=ax.transAxes, fontsize=12)\n",
    "                    ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "        \n",
    "        plt.suptitle('Mean Stride Length vs Success Rate by Trial/Condition (Colored by Motor Noise)' if has_motor_noise \n",
    "                     else 'Mean Stride Length vs Success Rate by Trial/Condition', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.population_plots_dir / 'mean_stride_length_vs_success_rate.png', \n",
    "                   dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_age_vs_mean_stride_length_enhanced(self, df: pd.DataFrame):\n",
    "        \"\"\"Enhanced age vs mean stride length by trial/condition with motor noise coloring.\"\"\"\n",
    "        \n",
    "        msl_columns = [col for col in df.columns if '_msl_' in col and '_const' in col]\n",
    "        if not msl_columns:\n",
    "            print(\"   ⚠️ No mean stride length columns found\")\n",
    "            return\n",
    "        \n",
    "        trials = ['vis1', 'invis', 'vis2']\n",
    "        conditions = ['max', 'min']\n",
    "        has_motor_noise = 'mot_noise' in df.columns\n",
    "        \n",
    "        fig, axes = plt.subplots(len(trials), len(conditions), figsize=(12, 4*len(trials)))\n",
    "        if len(trials) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, trial in enumerate(trials):\n",
    "            for j, condition in enumerate(conditions):\n",
    "                ax = axes[i, j]\n",
    "                col = f'{trial}_msl_{condition}_const'\n",
    "                \n",
    "                if col in df.columns:\n",
    "                    cols_to_use = ['age', col] + (['mot_noise'] if has_motor_noise else [])\n",
    "                    valid_data = df[cols_to_use].dropna()\n",
    "                    \n",
    "                    if not valid_data.empty:\n",
    "                        if has_motor_noise:\n",
    "                            scatter = ax.scatter(valid_data['age'], valid_data[col], \n",
    "                                               c=valid_data['mot_noise'], cmap='plasma', \n",
    "                                               alpha=0.7, s=60, edgecolors='white', linewidths=0.5)\n",
    "                            if i == 0 and j == len(conditions) - 1:\n",
    "                                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                                cbar.set_label('Motor Noise', rotation=270, labelpad=15)\n",
    "                        else:\n",
    "                            trial_colors = {'vis1': '#1f77b4', 'invis': '#ff7f0e', 'vis2': '#2ca02c'}\n",
    "                            ax.scatter(valid_data['age'], valid_data[col], \n",
    "                                     alpha=0.7, s=60, color=trial_colors.get(trial, 'steelblue'),\n",
    "                                     edgecolors='white', linewidths=0.5)\n",
    "                        \n",
    "                        # Add trend line and correlation\n",
    "                        self._add_trendline(ax, valid_data['age'], valid_data[col])\n",
    "                        \n",
    "                        ax.set_xlabel('Age (years)')\n",
    "                        ax.set_ylabel('Mean Stride Length')\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, 'No Data', ha='center', va='center',\n",
    "                               transform=ax.transAxes, fontsize=12)\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, 'Column Not Found', ha='center', va='center',\n",
    "                           transform=ax.transAxes, fontsize=12)\n",
    "                    ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "        \n",
    "        plt.suptitle('Age vs Mean Stride Length by Trial/Condition (Colored by Motor Noise)' if has_motor_noise \n",
    "                     else 'Age vs Mean Stride Length by Trial/Condition', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.population_plots_dir / 'age_vs_mean_stride_length_enhanced.png', \n",
    "                   dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_age_vs_mean_error_enhanced(self, df: pd.DataFrame):\n",
    "        \"\"\"Enhanced age vs mean error by trial/condition with motor noise coloring.\"\"\"\n",
    "        \n",
    "        error_columns = [col for col in df.columns if '_error_' in col and '_const' in col]\n",
    "        if not error_columns:\n",
    "            print(\"   ⚠️ No mean error columns found\")\n",
    "            return\n",
    "        \n",
    "        trials = ['vis1', 'invis', 'vis2']\n",
    "        conditions = ['max', 'min']\n",
    "        has_motor_noise = 'mot_noise' in df.columns\n",
    "        \n",
    "        fig, axes = plt.subplots(len(trials), len(conditions), figsize=(12, 4*len(trials)))\n",
    "        if len(trials) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, trial in enumerate(trials):\n",
    "            for j, condition in enumerate(conditions):\n",
    "                ax = axes[i, j]\n",
    "                col = f'{trial}_error_{condition}_const'\n",
    "                \n",
    "                if col in df.columns:\n",
    "                    cols_to_use = ['age', col] + (['mot_noise'] if has_motor_noise else [])\n",
    "                    valid_data = df[cols_to_use].dropna()\n",
    "                    \n",
    "                    if not valid_data.empty:\n",
    "                        if has_motor_noise:\n",
    "                            scatter = ax.scatter(valid_data['age'], valid_data[col], \n",
    "                                               c=valid_data['mot_noise'], alpha=0.7, s=60,\n",
    "                                               edgecolors='white', linewidths=0.5)\n",
    "                            if i == 0 and j == len(conditions) - 1:\n",
    "                                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                                cbar.set_label('Motor Noise', rotation=270, labelpad=15)\n",
    "                        else:\n",
    "                            trial_colors = {'vis1': '#1f77b4', 'invis': '#ff7f0e', 'vis2': '#2ca02c'}\n",
    "                            ax.scatter(valid_data['age'], valid_data[col], \n",
    "                                     alpha=0.7, s=60, color=trial_colors.get(trial, 'steelblue'),\n",
    "                                     edgecolors='white', linewidths=0.5)\n",
    "                        \n",
    "                        # Add trend line and correlation\n",
    "                        self._add_trendline(ax, valid_data['age'], valid_data[col])\n",
    "                        \n",
    "                        # Add horizontal line at zero (perfect accuracy)\n",
    "                        ax.axhline(y=0, color='green', linestyle='--', alpha=0.5, \n",
    "                                  label='Perfect Accuracy (Error = 0)')\n",
    "                        \n",
    "                        ax.set_xlabel('Age (years)')\n",
    "                        ax.set_ylabel('Mean Error (Stride Length - Target)')\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                        ax.set_ylim(-0.5, 0.5)\n",
    "                        \n",
    "                        # Add legend only to first subplot to avoid clutter\n",
    "                        if i == 0 and j == 0:\n",
    "                            ax.legend(loc='upper right', fontsize=9)\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, 'No Data', ha='center', va='center',\n",
    "                               transform=ax.transAxes, fontsize=12)\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, 'Column Not Found', ha='center', va='center',\n",
    "                           transform=ax.transAxes, fontsize=12)\n",
    "                    ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "        \n",
    "        plt.suptitle('Age vs Mean Error by Trial/Condition (Colored by Motor Noise)' if has_motor_noise \n",
    "                     else 'Age vs Mean Error by Trial/Condition', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.population_plots_dir / 'age_vs_mean_error_enhanced.png', \n",
    "                   dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_mean_error_vs_success_rate_enhanced(self, df: pd.DataFrame):\n",
    "        \"\"\"Enhanced mean error vs success rate by trial/condition with motor noise coloring.\"\"\"\n",
    "        \n",
    "        error_columns = [col for col in df.columns if '_error_' in col and '_const' in col]\n",
    "        sr_columns = [col for col in df.columns if '_sr_' in col and '_const' in col]\n",
    "        \n",
    "        if not error_columns or not sr_columns:\n",
    "            print(\"   ⚠️ Missing error or success rate columns\")\n",
    "            return\n",
    "        \n",
    "        trials = ['vis1', 'invis', 'vis2']\n",
    "        conditions = ['max', 'min']\n",
    "        has_motor_noise = 'mot_noise' in df.columns\n",
    "        has_age = 'age' in df.columns\n",
    "        \n",
    "        fig, axes = plt.subplots(len(trials), len(conditions), figsize=(12, 4*len(trials)))\n",
    "        if len(trials) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, trial in enumerate(trials):\n",
    "            for j, condition in enumerate(conditions):\n",
    "                ax = axes[i, j]\n",
    "                error_col = f'{trial}_error_{condition}_const'\n",
    "                sr_col = f'{trial}_sr_{condition}_const'\n",
    "                \n",
    "                if error_col in df.columns and sr_col in df.columns:\n",
    "                    cols_to_use = [error_col, sr_col] + (['mot_noise'] if has_motor_noise else []) + (['age'] if has_age else [])\n",
    "                    valid_data = df[cols_to_use].dropna()\n",
    "                    \n",
    "                    if not valid_data.empty:\n",
    "                        if has_motor_noise:\n",
    "                            scatter = ax.scatter(valid_data[error_col], valid_data[sr_col], \n",
    "                                               c=valid_data['mot_noise'], cmap='plasma', \n",
    "                                               alpha=0.7, s=60, edgecolors='white', linewidths=0.5)\n",
    "                            if i == 0 and j == len(conditions) - 1:\n",
    "                                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                                cbar.set_label('Motor Noise', rotation=270, labelpad=15)\n",
    "                        elif has_age:\n",
    "                            scatter = ax.scatter(valid_data[error_col], valid_data[sr_col], \n",
    "                                               c=valid_data['age'], cmap='viridis', \n",
    "                                               alpha=0.7, s=60, edgecolors='white', linewidths=0.5)\n",
    "                            if i == 0 and j == len(conditions) - 1:\n",
    "                                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                                cbar.set_label('Age (years)', rotation=270, labelpad=15)\n",
    "                        else:\n",
    "                            trial_colors = {'vis1': '#1f77b4', 'invis': '#ff7f0e', 'vis2': '#2ca02c'}\n",
    "                            ax.scatter(valid_data[error_col], valid_data[sr_col], \n",
    "                                     alpha=0.7, s=60, color=trial_colors.get(trial, 'steelblue'),\n",
    "                                     edgecolors='white', linewidths=0.5)\n",
    "                        \n",
    "                        # Add trend line and correlation\n",
    "                        self._add_trendline(ax, valid_data[error_col], valid_data[sr_col])\n",
    "                        \n",
    "                        # Add reference lines\n",
    "                        ax.axvline(x=0, color='green', linestyle='--', alpha=0.5, \n",
    "                                  label='Perfect Accuracy (Error = 0)')\n",
    "                        ax.axhline(y=0.68, color='red', linestyle='--', alpha=0.5, \n",
    "                                  label='68% Success Threshold')\n",
    "                        \n",
    "                        ax.set_xlabel('Mean Error (Stride Length - Target)')\n",
    "                        ax.set_ylabel('Success Rate')\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                        ax.set_ylim(-0.05, 1.05)\n",
    "                        ax.set_xlim(-0.5, 0.5)\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                        \n",
    "                        # Add legend only to first subplot to avoid clutter\n",
    "                        if i == 0 and j == 0:\n",
    "                            ax.legend(loc='upper right', fontsize=9)\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, 'No Data', ha='center', va='center',\n",
    "                               transform=ax.transAxes, fontsize=12)\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, 'Columns Not Found', ha='center', va='center',\n",
    "                           transform=ax.transAxes, fontsize=12)\n",
    "                    ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "        \n",
    "        color_label = 'Motor Noise' if has_motor_noise else ('Age' if has_age else '')\n",
    "        title_suffix = f' (Colored by {color_label})' if color_label else ''\n",
    "        \n",
    "        plt.suptitle(f'Mean Error vs Success Rate by Trial/Condition{title_suffix}', \n",
    "                     fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.population_plots_dir / 'mean_error_vs_success_rate_enhanced.png', \n",
    "                   dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_motor_noise_vs_success_rates_enhanced(self, df: pd.DataFrame):\n",
    "        \"\"\"Motor noise vs success rates by trial/condition with age coloring.\"\"\"\n",
    "        \n",
    "        if 'mot_noise' not in df.columns:\n",
    "            print(\"   ⚠️ No motor noise data available\")\n",
    "            return\n",
    "        \n",
    "        sr_columns = [col for col in df.columns if '_sr_' in col and '_const' in col]\n",
    "        if not sr_columns:\n",
    "            print(\"   ⚠️ No success rate columns found\")\n",
    "            return\n",
    "        \n",
    "        trials = ['vis1', 'invis', 'vis2']\n",
    "        conditions = ['max', 'min']\n",
    "        has_age = 'age' in df.columns\n",
    "        \n",
    "        fig, axes = plt.subplots(len(trials), len(conditions), figsize=(12, 4*len(trials)))\n",
    "        if len(trials) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, trial in enumerate(trials):\n",
    "            for j, condition in enumerate(conditions):\n",
    "                ax = axes[i, j]\n",
    "                col = f'{trial}_sr_{condition}_const'\n",
    "                \n",
    "                if col in df.columns:\n",
    "                    cols_to_use = ['mot_noise', col] + (['age'] if has_age else [])\n",
    "                    valid_data = df[cols_to_use].dropna()\n",
    "                    \n",
    "                    if not valid_data.empty:\n",
    "                        if has_age:\n",
    "                            scatter = ax.scatter(valid_data['mot_noise'], valid_data[col], \n",
    "                                               c=valid_data['age'], alpha=0.7, s=60, \n",
    "                                               edgecolors='white', linewidths=0.5)\n",
    "                            if i == 0 and j == len(conditions) - 1:\n",
    "                                cbar = plt.colorbar(scatter, ax=ax)\n",
    "                                cbar.set_label('Age (years)', rotation=270, labelpad=15)\n",
    "                        else:\n",
    "                            ax.scatter(valid_data['mot_noise'], valid_data[col], \n",
    "                                     alpha=0.7, s=60, color='steelblue',\n",
    "                                     edgecolors='white', linewidths=0.5)\n",
    "                        \n",
    "                        # Add threshold lines\n",
    "                        motor_noise_threshold = getattr(self.config, 'MOTOR_NOISE_THRESHOLD', 0.3)\n",
    "                        success_threshold = getattr(self.config, 'SUCCESS_RATE_THRESHOLD', 0.68)\n",
    "                        \n",
    "                        ax.axvline(x=motor_noise_threshold, color='red', \n",
    "                                  linestyle='--', alpha=0.7, linewidth=2,\n",
    "                                  label=f'Motor Noise Threshold')\n",
    "                        ax.axhline(y=success_threshold, color='green', \n",
    "                                  linestyle='--', alpha=0.7, linewidth=2,\n",
    "                                  label=f'Success Threshold')\n",
    "                        \n",
    "                        ax.set_xlabel('Motor Noise')\n",
    "                        ax.set_ylabel('Success Rate')\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                        ax.set_ylim(-0.05, 1.05)\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                        \n",
    "                        # Add legend only to the first subplot to avoid clutter\n",
    "                        if i == 0 and j == 0:\n",
    "                            ax.legend(loc='upper right', fontsize=9)\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, 'No Data', ha='center', va='center',\n",
    "                               transform=ax.transAxes, fontsize=12)\n",
    "                        ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, 'Column Not Found', ha='center', va='center',\n",
    "                           transform=ax.transAxes, fontsize=12)\n",
    "                    ax.set_title(f'{trial.upper()}: {condition.capitalize()} Target')\n",
    "        \n",
    "        plt.suptitle('Motor Noise vs Success Rates by Trial/Condition (Colored by Age)' if has_age \n",
    "                     else 'Motor Noise vs Success Rates by Trial/Condition', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.population_plots_dir / 'motor_noise_vs_success_rates_enhanced.png', \n",
    "                   dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_age_vs_motor_noise(self, df: pd.DataFrame):\n",
    "        \"\"\"Plot age vs motor noise relationship with robust error handling.\"\"\"\n",
    "        \n",
    "        if 'age' not in df.columns or 'mot_noise' not in df.columns:\n",
    "            print(\"   ⚠️ Missing age or motor noise columns\")\n",
    "            return\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        try:\n",
    "            # Convert to numeric and drop NaN values\n",
    "            age_data = pd.to_numeric(df['age'], errors='coerce')\n",
    "            motor_noise_data = pd.to_numeric(df['mot_noise'], errors='coerce')\n",
    "            \n",
    "            plot_data = pd.DataFrame({\n",
    "                'age': age_data,\n",
    "                'mot_noise': motor_noise_data\n",
    "            }).dropna()\n",
    "            \n",
    "            if plot_data.empty or len(plot_data) < 2:\n",
    "                plt.text(0.5, 0.5, 'Insufficient valid data', ha='center', va='center',\n",
    "                        transform=plt.gca().transAxes, fontsize=14)\n",
    "                plt.title('Age vs Motor Noise - Insufficient Data')\n",
    "            else:\n",
    "                # Create scatter plot\n",
    "                plt.scatter(plot_data['age'], plot_data['mot_noise'], \n",
    "                           alpha=0.6, s=60, color='steelblue', \n",
    "                           edgecolors='white', linewidths=0.5)\n",
    "                \n",
    "                # Add trend line and correlation\n",
    "                self._add_trendline(plt.gca(), plot_data['age'], plot_data['mot_noise'])\n",
    "                \n",
    "                # Add motor noise threshold line\n",
    "                motor_noise_threshold = getattr(self.config, 'MOTOR_NOISE_THRESHOLD', 0.3)\n",
    "                plt.axhline(y=motor_noise_threshold, color='red', linestyle='--', alpha=0.7, \n",
    "                           label=f'Threshold ({motor_noise_threshold})')\n",
    "                \n",
    "                plt.xlabel('Age (years)', fontsize=12)\n",
    "                plt.ylabel('Motor Noise', fontsize=12)\n",
    "                plt.title('Age vs Motor Noise Relationship', fontsize=14, fontweight='bold')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.legend()\n",
    "                \n",
    "                # Set reasonable axis limits\n",
    "                age_range = plot_data['age'].max() - plot_data['age'].min()\n",
    "                motor_range = plot_data['mot_noise'].max() - plot_data['mot_noise'].min()\n",
    "                \n",
    "                plt.xlim(plot_data['age'].min() - age_range*0.05, \n",
    "                        plot_data['age'].max() + age_range*0.05)\n",
    "                plt.ylim(max(0, plot_data['mot_noise'].min() - motor_range*0.05), \n",
    "                        plot_data['mot_noise'].max() + motor_range*0.05)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ Error in age vs motor noise plot: {e}\")\n",
    "            plt.text(0.5, 0.5, f'Error creating plot:\\\\n{str(e)}', \n",
    "                    ha='center', va='center', transform=plt.gca().transAxes, \n",
    "                    fontsize=12, style='italic')\n",
    "            plt.title('Age vs Motor Noise - Error')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.population_plots_dir / 'age_vs_motor_noise.png', \n",
    "                   dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_correlation_matrix(self, df: pd.DataFrame):\n",
    "        \"\"\"Plot correlation matrix of key variables.\"\"\"\n",
    "        \n",
    "        key_cols = ['age']\n",
    "        if 'mot_noise' in df.columns:\n",
    "            key_cols.append('mot_noise')\n",
    "        if 'pref_asymmetry' in df.columns:\n",
    "            key_cols.append('pref_asymmetry')\n",
    "        \n",
    "        # Add success rate columns\n",
    "        sr_cols = [col for col in df.columns if '_sr_' in col and '_const' in col]\n",
    "        key_cols.extend(sr_cols[:6])  # Limit to prevent overcrowding\n",
    "        \n",
    "        if len(key_cols) > 1:\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            \n",
    "            corr_matrix = df[key_cols].corr()\n",
    "            mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "            \n",
    "            sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0,\n",
    "                       square=True, linewidths=0.5, fmt='.2f')\n",
    "            \n",
    "            plt.title('Correlation Matrix of Key Variables', fontsize=16, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            plt.savefig(self.population_plots_dir / 'correlation_matrix.png',\n",
    "                       dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "    def _plot_success_rate_overview(self, df: pd.DataFrame, sr_cols: List[str]):\n",
    "        \"\"\"Plot success rate overview across conditions.\"\"\"\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # 1. Mean success rates by condition\n",
    "        sr_means = [df[col].mean() for col in sr_cols[:8]]  # Limit for readability\n",
    "        sr_names = [col.replace('_sr_', ' ').replace('_const', '') for col in sr_cols[:8]]\n",
    "        \n",
    "        bars = ax1.bar(range(len(sr_names)), sr_means, alpha=0.7, color='steelblue')\n",
    "        ax1.set_title('Mean Success Rates by Condition')\n",
    "        ax1.set_ylabel('Success Rate')\n",
    "        ax1.set_ylim(0, 1)\n",
    "        ax1.set_xticks(range(len(sr_names)))\n",
    "        ax1.set_xticklabels(sr_names, rotation=45, ha='right')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{height:.2f}', ha='center', va='bottom')\n",
    "        \n",
    "        # 2. Success rate distributions\n",
    "        plot_data = []\n",
    "        for col in sr_cols[:6]:  # Limit for readability\n",
    "            trial_type = col.split('_')[0]\n",
    "            condition = col.split('_')[2]\n",
    "            values = df[col].dropna()\n",
    "            for val in values:\n",
    "                plot_data.append({\n",
    "                    'condition': f'{trial_type}_{condition}',\n",
    "                    'success_rate': val\n",
    "                })\n",
    "        \n",
    "        if plot_data:\n",
    "            plot_df = pd.DataFrame(plot_data)\n",
    "            sns.boxplot(data=plot_df, x='condition', y='success_rate', ax=ax2)\n",
    "            ax2.set_title('Success Rate Distributions')\n",
    "            ax2.set_ylabel('Success Rate')\n",
    "            ax2.set_ylim(0, 1)\n",
    "            plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.population_plots_dir / 'success_rate_overview.png',\n",
    "                   dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # ==========================================================================\n",
    "    # STATISTICAL ANALYSIS PLOTTING METHODS\n",
    "    # ==========================================================================\n",
    "\n",
    "    def _plot_feature_importance_analysis(self):\n",
    "        \"\"\"Plot feature importance analysis if regression results are available.\"\"\"\n",
    "        \n",
    "        if not hasattr(self.analysis, 'analyzer'):\n",
    "            print(\"   ⚠️ No analyzer available for feature importance\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Try to run a quick regression analysis\n",
    "            regression_results = self.analysis.analyzer.run_regression_analysis()\n",
    "            \n",
    "            if 'feature_importances' in regression_results:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                \n",
    "                features = list(regression_results['feature_importances'].keys())\n",
    "                importances = list(regression_results['feature_importances'].values())\n",
    "                \n",
    "                bars = plt.bar(features, importances, alpha=0.7, color='steelblue')\n",
    "                plt.title('Feature Importance for Success Rate Prediction')\n",
    "                plt.ylabel('Importance')\n",
    "                plt.xticks(rotation=45, ha='right')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                \n",
    "                # Add value labels\n",
    "                for bar, importance in zip(bars, importances):\n",
    "                    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,\n",
    "                            f'{importance:.3f}', ha='center', va='bottom')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(self.statistical_plots_dir / 'feature_importance_analysis.png',\n",
    "                           dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "                plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ Feature importance analysis failed: {e}\")\n",
    "\n",
    "    def _plot_age_effects_summary(self):\n",
    "        \"\"\"Plot summary of age effects on performance measures.\"\"\"\n",
    "        \n",
    "        df = self.filtered_df\n",
    "        if 'age' not in df.columns:\n",
    "            print(\"   ⚠️ No age data available for age effects analysis\")\n",
    "            return\n",
    "        \n",
    "        # Calculate age effects for success rate measures\n",
    "        sr_cols = [col for col in df.columns if '_sr_' in col and '_const' in col]\n",
    "        age_effects = []\n",
    "        \n",
    "        for col in sr_cols[:10]:  # Limit for readability\n",
    "            valid_data = df[['age', col]].dropna()\n",
    "            if len(valid_data) > 10:\n",
    "                try:\n",
    "                    r, p = pearsonr(valid_data['age'], valid_data[col])\n",
    "                    age_effects.append({\n",
    "                        'measure': col.replace('_sr_', ' ').replace('_const', ''),\n",
    "                        'correlation': r,\n",
    "                        'p_value': p,\n",
    "                        'significant': p < 0.05\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if not age_effects:\n",
    "            print(\"   ⚠️ No valid age effects calculated\")\n",
    "            return\n",
    "        \n",
    "        # Sort by correlation strength\n",
    "        age_effects.sort(key=lambda x: abs(x['correlation']), reverse=True)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "        \n",
    "        # Correlation plot\n",
    "        measures = [e['measure'] for e in age_effects]\n",
    "        correlations = [e['correlation'] for e in age_effects]\n",
    "        significant = [e['significant'] for e in age_effects]\n",
    "        \n",
    "        colors = ['red' if sig else 'blue' for sig in significant]\n",
    "        bars = ax1.barh(range(len(measures)), correlations, color=colors, alpha=0.7)\n",
    "        ax1.set_yticks(range(len(measures)))\n",
    "        ax1.set_yticklabels([m.replace('_', ' ') for m in measures])\n",
    "        ax1.set_xlabel('Correlation with Age')\n",
    "        ax1.set_title('Age Effect Sizes')\n",
    "        ax1.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add legend\n",
    "        red_patch = plt.Rectangle((0,0),1,1, facecolor='red', alpha=0.7, label='Significant (p < 0.05)')\n",
    "        blue_patch = plt.Rectangle((0,0),1,1, facecolor='blue', alpha=0.7, label='Not significant')\n",
    "        ax1.legend(handles=[red_patch, blue_patch])\n",
    "        \n",
    "        # P-value plot\n",
    "        p_values = [e['p_value'] for e in age_effects]\n",
    "        log_p = [-np.log10(p) for p in p_values]\n",
    "        bars2 = ax2.barh(range(len(measures)), log_p, color=colors, alpha=0.7)\n",
    "        ax2.set_yticks(range(len(measures)))\n",
    "        ax2.set_yticklabels([m.replace('_', ' ') for m in measures])\n",
    "        ax2.set_xlabel('-log10(p-value)')\n",
    "        ax2.set_title('Statistical Significance')\n",
    "        ax2.axvline(x=-np.log10(0.05), color='red', linestyle='--', alpha=0.8, label='p = 0.05')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.statistical_plots_dir / 'age_effects_summary.png',\n",
    "                   dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_trial_comparisons(self):\n",
    "        \"\"\"Plot comparisons between trial types.\"\"\"\n",
    "        \n",
    "        df = self.filtered_df\n",
    "        \n",
    "        # Compare success rates across trial types\n",
    "        comparison_data = []\n",
    "        \n",
    "        for condition in ['max', 'min']:\n",
    "            for trial in ['vis1', 'invis', 'vis2']:\n",
    "                col = f'{trial}_sr_{condition}_const'\n",
    "                if col in df.columns:\n",
    "                    values = df[col].dropna()\n",
    "                    for val in values:\n",
    "                        comparison_data.append({\n",
    "                            'trial_type': trial,\n",
    "                            'condition': condition,\n",
    "                            'success_rate': val\n",
    "                        })\n",
    "        \n",
    "        if not comparison_data:\n",
    "            print(\"   ⚠️ No trial comparison data available\")\n",
    "            return\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # 1. Box plot by trial type\n",
    "        sns.boxplot(data=comparison_df, x='trial_type', y='success_rate', ax=axes[0, 0])\n",
    "        axes[0, 0].set_title('Success Rates by Trial Type')\n",
    "        axes[0, 0].set_ylabel('Success Rate')\n",
    "        axes[0, 0].set_ylim(-0.05, 1.05)\n",
    "        \n",
    "        # 2. Box plot by condition\n",
    "        sns.boxplot(data=comparison_df, x='condition', y='success_rate', ax=axes[0, 1])\n",
    "        axes[0, 1].set_title('Success Rates by Target Condition')\n",
    "        axes[0, 1].set_ylabel('Success Rate')\n",
    "        axes[0, 1].set_ylim(-0.05, 1.05)\n",
    "        \n",
    "        # 3. Box plot by trial type and condition\n",
    "        sns.boxplot(data=comparison_df, x='trial_type', y='success_rate', \n",
    "                   hue='condition', ax=axes[1, 0])\n",
    "        axes[1, 0].set_title('Success Rates by Trial Type and Condition')\n",
    "        axes[1, 0].set_ylabel('Success Rate')\n",
    "        axes[1, 0].set_ylim(-0.05, 1.05)\n",
    "        \n",
    "        # 4. Violin plot for distribution shapes\n",
    "        sns.violinplot(data=comparison_df, x='trial_type', y='success_rate', \n",
    "                      hue='condition', ax=axes[1, 1])\n",
    "        axes[1, 1].set_title('Success Rate Distributions')\n",
    "        axes[1, 1].set_ylabel('Success Rate')\n",
    "        axes[1, 1].set_ylim(-0.05, 1.05)\n",
    "        \n",
    "        plt.suptitle('Trial Type Comparisons Across Conditions', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.savefig(self.statistical_plots_dir / 'trial_comparisons.png',\n",
    "                   dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def generate_summary_dashboard(self) -> Dict:\n",
    "        \"\"\"Generate comprehensive summary dashboard.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            df = self.filtered_df\n",
    "            \n",
    "            fig = plt.figure(figsize=(16, 12))\n",
    "            gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "            \n",
    "            # 1. Age distribution\n",
    "            ax1 = fig.add_subplot(gs[0, 0])\n",
    "            if 'age' in df.columns:\n",
    "                df['age'].hist(bins=range(7, 19), ax=ax1, alpha=0.7, color='skyblue')\n",
    "                ax1.set_title('Age Distribution')\n",
    "                ax1.set_xlabel('Age (years)')\n",
    "                ax1.set_ylabel('Count')\n",
    "            \n",
    "            # 2. Motor noise distribution\n",
    "            ax2 = fig.add_subplot(gs[0, 1])\n",
    "            if 'mot_noise' in df.columns:\n",
    "                df['mot_noise'].hist(bins=15, ax=ax2, alpha=0.7, color='lightcoral')\n",
    "                motor_noise_threshold = getattr(self.config, 'MOTOR_NOISE_THRESHOLD', 0.3)\n",
    "                ax2.axvline(motor_noise_threshold, color='red', linestyle='--', \n",
    "                           label=f\"Threshold ({motor_noise_threshold})\")\n",
    "                ax2.set_title('Motor Noise Distribution')\n",
    "                ax2.set_xlabel('Motor Noise')\n",
    "                ax2.set_ylabel('Count')\n",
    "                ax2.legend()\n",
    "            \n",
    "            # 3. Success rates overview\n",
    "            ax3 = fig.add_subplot(gs[0, 2])\n",
    "            sr_cols = [col for col in df.columns if '_sr_' in col and '_const' in col]\n",
    "            if sr_cols:\n",
    "                sr_means = [df[col].mean() for col in sr_cols[:6]]\n",
    "                sr_names = [col.replace('_sr_', ' ').replace('_const', '') for col in sr_cols[:6]]\n",
    "                \n",
    "                bars = ax3.bar(range(len(sr_names)), sr_means, alpha=0.7)\n",
    "                ax3.set_title('Mean Success Rates')\n",
    "                ax3.set_ylabel('Success Rate')\n",
    "                ax3.set_ylim(0, 1)\n",
    "                ax3.set_xticks(range(len(sr_names)))\n",
    "                ax3.set_xticklabels(sr_names, rotation=45, ha='right')\n",
    "            \n",
    "            # 4. Summary statistics table\n",
    "            ax4 = fig.add_subplot(gs[1:, :])\n",
    "            ax4.axis('tight')\n",
    "            ax4.axis('off')\n",
    "            \n",
    "            # Create summary table\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            motor_noise_threshold = getattr(self.config, 'MOTOR_NOISE_THRESHOLD', 0.3)\n",
    "            \n",
    "            summary_data = [\n",
    "                ['Total Subjects', f\"{len(df)}\"],\n",
    "                ['Age Range', f\"{df['age'].min():.1f} - {df['age'].max():.1f} years\" if 'age' in df.columns else \"N/A\"],\n",
    "                ['Mean Age ± SD', f\"{df['age'].mean():.1f} ± {df['age'].std():.1f} years\" if 'age' in df.columns else \"N/A\"],\n",
    "                ['Motor Noise Range', f\"{df['mot_noise'].min():.3f} - {df['mot_noise'].max():.3f}\" if 'mot_noise' in df.columns else \"N/A\"],\n",
    "                ['Success Rate Measures', f\"{len(sr_cols)}\"],\n",
    "                ['High Motor Noise Subjects', f\"{(df['mot_noise'] > motor_noise_threshold).sum()}\" if 'mot_noise' in df.columns else \"N/A\"],\n",
    "                ['Enhanced Population Plots', \"✅ Age vs SR, Age vs SD, MSL vs SR (by trial/condition)\"],\n",
    "                ['Motor Noise Coloring', \"✅ All plots colored by motor noise level\"],\n",
    "                ['Analysis Timestamp', timestamp]\n",
    "            ]\n",
    "            \n",
    "            table = ax4.table(cellText=summary_data, colLabels=['Metric', 'Value'],\n",
    "                             cellLoc='left', loc='center')\n",
    "            table.auto_set_font_size(False)\n",
    "            table.set_fontsize(12)\n",
    "            table.scale(1.2, 2)\n",
    "            ax4.set_title('Enhanced Motor Learning Analysis Summary', fontsize=16, fontweight='bold', pad=20)\n",
    "            \n",
    "            plt.suptitle('Enhanced Motor Learning Analysis Dashboard', fontsize=18, y=0.95)\n",
    "            \n",
    "            # Save dashboard\n",
    "            dashboard_file = self.statistical_plots_dir / f'analysis_dashboard_{timestamp}.png'\n",
    "            plt.savefig(dashboard_file, dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"   Generated summary dashboard: {dashboard_file.name}\")\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'file': str(dashboard_file)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ Dashboard generation failed: {e}\")\n",
    "            return {'success': False, 'error': str(e)}\n",
    "\n",
    "    # ==========================================================================\n",
    "    # INDIVIDUAL PLOTTING METHODS (EXISTING)\n",
    "    # ==========================================================================\n",
    "\n",
    "    def plot_all_individual_stride_changes(self, trial_types: List[str] = None, \n",
    "                                         subject_ids: List[str] = None,\n",
    "                                         save_summary: bool = True,\n",
    "                                         max_subjects: int = None) -> Dict:\n",
    "        \"\"\"Generate stride change distribution plots for all participants.\"\"\"\n",
    "        \n",
    "        if trial_types is None:\n",
    "            trial_types = ['vis1', 'invis', 'vis2']\n",
    "        \n",
    "        if subject_ids is None:\n",
    "            subject_ids = list(self.data_manager.processed_data.keys())\n",
    "        \n",
    "        # Limit subjects if requested\n",
    "        if max_subjects and len(subject_ids) > max_subjects:\n",
    "            subject_ids = subject_ids[:max_subjects]\n",
    "            print(f\"🔄 Limited to first {max_subjects} subjects for testing\")\n",
    "        \n",
    "        print(f\"🎯 Generating individual stride change plots...\")\n",
    "        print(f\"   📊 {len(subject_ids)} subjects\")\n",
    "        print(f\"   🎮 Trial types: {trial_types}\")\n",
    "        print(f\"   💾 Saving to: {self.individual_plots_dir}\")\n",
    "        \n",
    "        all_stats = {}\n",
    "        successful_plots = 0\n",
    "        failed_plots = 0\n",
    "        \n",
    "        # Progress bar for subjects\n",
    "        for subject_id in tqdm(subject_ids, desc=\"Processing subjects\"):\n",
    "            subject_stats = {}\n",
    "            \n",
    "            # Get subject metadata\n",
    "            if subject_id in self.data_manager.processed_data:\n",
    "                age = self.data_manager.processed_data[subject_id]['metadata'].get('age_months', np.nan) / 12\n",
    "                subject_stats['age'] = age\n",
    "            \n",
    "            # Process each trial type\n",
    "            for trial_type in trial_types:\n",
    "                try:\n",
    "                    # Use our own implementation\n",
    "                    stats = self._plot_individual_stride_change_internal(\n",
    "                        subject_id, trial_type, save=True, show_stats=False\n",
    "                    )\n",
    "                    \n",
    "                    if stats:\n",
    "                        subject_stats[trial_type] = stats\n",
    "                        successful_plots += 1\n",
    "                    else:\n",
    "                        failed_plots += 1\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   ⚠️ Error plotting {subject_id} {trial_type}: {str(e)}\")\n",
    "                    failed_plots += 1\n",
    "                    continue\n",
    "            \n",
    "            if subject_stats:\n",
    "                all_stats[subject_id] = subject_stats\n",
    "        \n",
    "        print(f\"✅ Completed: {successful_plots} successful plots, {failed_plots} failed\")\n",
    "        \n",
    "        # Save summary if requested\n",
    "        if save_summary:\n",
    "            self._save_stride_analysis_summary(all_stats)\n",
    "        \n",
    "        return all_stats\n",
    "\n",
    "    def _plot_individual_stride_change_internal(self, subject_id: str, trial_types: List[str] = None,\n",
    "                                               stride_col: str = 'Sum of gains and steps',\n",
    "                                               figsize: Tuple[int, int] = (16, 18), \n",
    "                                               save: bool = True, alpha: float = 0.7,\n",
    "                                               show_stats: bool = False) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Internal method for plotting individual stride changes with FIXED 3x2 grid layout.\n",
    "        Always creates exactly 6 subplots (3 trials × 2 conditions) regardless of data availability.\n",
    "        \"\"\"\n",
    "        \n",
    "        if trial_types is None:\n",
    "            trial_types = ['vis1', 'invis', 'vis2']\n",
    "        \n",
    "        # Check if subject exists\n",
    "        if subject_id not in self.data_manager.processed_data:\n",
    "            return None\n",
    "        \n",
    "        # Get subject age for title\n",
    "        subject_age = self.data_manager.processed_data[subject_id]['metadata'].get('age_months', np.nan) / 12\n",
    "        \n",
    "        # FIXED: Always create 3x2 grid regardless of data availability\n",
    "        fig, axes = plt.subplots(3, 2, figsize=figsize, sharey=False)\n",
    "        \n",
    "        # Define the fixed layout mapping\n",
    "        layout_mapping = {\n",
    "            'vis1': (0, 0, 0, 1),    # Row 0, columns 0 and 1\n",
    "            'invis': (1, 0, 1, 1),   # Row 1, columns 0 and 1  \n",
    "            'vis2': (2, 0, 2, 1)     # Row 2, columns 0 and 1\n",
    "        }\n",
    "        \n",
    "        # Condition names for column headers\n",
    "        condition_names = ['Upper Target (Max Constant)', 'Lower Target (Min Constant)']\n",
    "        \n",
    "        # Helper function to get period data\n",
    "        def get_period_data(df, constant_condition, length=20):\n",
    "            if df is None or df.empty:\n",
    "                return None\n",
    "                \n",
    "            min_target = df['Target size'].min()\n",
    "            target_tolerance = 0.001\n",
    "            \n",
    "            min_target_periods = df[df['Target size'] <= min_target + target_tolerance]\n",
    "            if min_target_periods.empty:\n",
    "                return None\n",
    "                \n",
    "            const_value = (\n",
    "                min_target_periods['Constant'].max() if constant_condition == 'max'\n",
    "                else min_target_periods['Constant'].min()\n",
    "            )\n",
    "            \n",
    "            period_data = min_target_periods[\n",
    "                np.isclose(min_target_periods['Constant'], const_value, rtol=1e-5)\n",
    "            ]\n",
    "            \n",
    "            if period_data.empty:\n",
    "                return None\n",
    "                \n",
    "            return period_data.tail(length)\n",
    "        \n",
    "        # Function to process and plot data for each condition\n",
    "        def plot_condition_data(ax, period_data, condition_name, const_type, trial_type, row, col):\n",
    "            # Set title and labels regardless of data availability\n",
    "            ax.set_title(f'{trial_type.upper()}: {condition_name}\\\\n(last 20 strides)', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "            ax.set_xlabel(f'Change in {stride_col.replace(\"_\", \" \")}', fontsize=11)\n",
    "            ax.set_ylabel('Probability Density', fontsize=11)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            if period_data is None or period_data.empty:\n",
    "                ax.text(0.5, 0.5, f'No {condition_name.split()[0].lower()}\\\\ntarget data available', \n",
    "                       ha='center', va='center', transform=ax.transAxes,\n",
    "                       fontsize=12, style='italic', color='gray',\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.5))\n",
    "                ax.set_xlim(-2, 2)\n",
    "                ax.set_ylim(0, 1)\n",
    "                return None\n",
    "            \n",
    "            # Sort by stride number and calculate stride length changes\n",
    "            period_sorted = period_data.sort_values('Stride Number').copy()\n",
    "            period_sorted['Delta'] = period_sorted[stride_col].diff().shift(-1)\n",
    "            period_sorted = period_sorted[:-1]  # Remove last row\n",
    "            \n",
    "            # Separate changes after success vs failure\n",
    "            success_deltas = period_sorted[period_sorted['Success'] == 1]['Delta'].dropna()\n",
    "            failure_deltas = period_sorted[period_sorted['Success'] == 0]['Delta'].dropna()\n",
    "            \n",
    "            if len(success_deltas) == 0 and len(failure_deltas) == 0:\n",
    "                ax.text(0.5, 0.5, f'No valid stride changes\\\\nfor {condition_name.split()[0].lower()} target', \n",
    "                       ha='center', va='center', transform=ax.transAxes,\n",
    "                       fontsize=12, style='italic', color='gray',\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.5))\n",
    "                ax.set_xlim(-2, 2)\n",
    "                ax.set_ylim(0, 1)\n",
    "                return None\n",
    "            \n",
    "            # Plot distributions using KDE or fallback methods\n",
    "            if len(success_deltas) > 0:\n",
    "                self._plot_distribution(ax, success_deltas, 'green', f'After Success (n={len(success_deltas)})', alpha)\n",
    "            \n",
    "            if len(failure_deltas) > 0:\n",
    "                self._plot_distribution(ax, failure_deltas, 'red', f'After Failure (n={len(failure_deltas)})', alpha)\n",
    "            \n",
    "            # Add mean lines and formatting\n",
    "            if len(success_deltas) > 0:\n",
    "                ax.axvline(success_deltas.mean(), color='darkgreen', linestyle='--', linewidth=2,\n",
    "                           label=f'Success Mean: {success_deltas.mean():.3f}')\n",
    "            \n",
    "            if len(failure_deltas) > 0:\n",
    "                ax.axvline(failure_deltas.mean(), color='darkred', linestyle='--', linewidth=2,\n",
    "                           label=f'Failure Mean: {failure_deltas.mean():.3f}')\n",
    "            \n",
    "            ax.axvline(0, color='black', linestyle='-', alpha=0.3, linewidth=1)\n",
    "            \n",
    "            # Success rate annotation\n",
    "            if len(period_sorted) > 0:\n",
    "                success_rate = period_sorted['Success'].mean()\n",
    "                ax.text(0.02, 0.98, f'Success Rate: {success_rate:.1%}', \n",
    "                       transform=ax.transAxes, fontsize=10, fontweight='bold',\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.8),\n",
    "                       verticalalignment='top', horizontalalignment='left')\n",
    "            \n",
    "            ax.legend(loc='upper right', fontsize=9)\n",
    "            \n",
    "            # Return statistics\n",
    "            return {\n",
    "                f'{const_type}_success_deltas': success_deltas.tolist() if len(success_deltas) > 0 else [],\n",
    "                f'{const_type}_failure_deltas': failure_deltas.tolist() if len(failure_deltas) > 0 else [],\n",
    "                f'{const_type}_success_mean': success_deltas.mean() if len(success_deltas) > 0 else None,\n",
    "                f'{const_type}_failure_mean': failure_deltas.mean() if len(failure_deltas) > 0 else None,\n",
    "                f'{const_type}_success_rate': period_sorted['Success'].mean(),\n",
    "                f'{const_type}_n_success': len(success_deltas),\n",
    "                f'{const_type}_n_failure': len(failure_deltas)\n",
    "            }\n",
    "        \n",
    "        # FIXED: Process all trial types in fixed positions\n",
    "        all_stats = {'subject_id': subject_id}\n",
    "        \n",
    "        for trial_type in trial_types:\n",
    "            # Get the fixed row and column positions for this trial type\n",
    "            if trial_type not in layout_mapping:\n",
    "                continue\n",
    "                \n",
    "            row_max, col_max, row_min, col_min = layout_mapping[trial_type]\n",
    "            \n",
    "            # Get trial data\n",
    "            trial_dict = self.data_manager.processed_data[subject_id]['trial_data'].get(trial_type)\n",
    "            if trial_dict is None:\n",
    "                df = None\n",
    "            else:\n",
    "                df = trial_dict.get('data')\n",
    "            \n",
    "            # Check required columns if data exists\n",
    "            if df is not None and not df.empty:\n",
    "                required_cols = [stride_col, 'Success', 'Stride Number', 'Target size', 'Constant']\n",
    "                missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "                if missing_cols:\n",
    "                    if show_stats:\n",
    "                        print(f\"Missing columns for {subject_id} {trial_type}: {missing_cols}\")\n",
    "                    df = None\n",
    "            \n",
    "            # Get data for both target conditions\n",
    "            max_const_data = get_period_data(df, 'max') if df is not None else None\n",
    "            min_const_data = get_period_data(df, 'min') if df is not None else None\n",
    "            \n",
    "            # Plot both conditions in their fixed positions\n",
    "            max_stats = plot_condition_data(\n",
    "                axes[row_max, col_max], max_const_data, condition_names[0], 'max', trial_type, row_max, col_max\n",
    "            )\n",
    "            min_stats = plot_condition_data(\n",
    "                axes[row_min, col_min], min_const_data, condition_names[1], 'min', trial_type, row_min, col_min\n",
    "            )\n",
    "            \n",
    "            # Combine statistics for this trial type\n",
    "            trial_stats = {}\n",
    "            if max_stats:\n",
    "                trial_stats.update(max_stats)\n",
    "            if min_stats:\n",
    "                trial_stats.update(min_stats)\n",
    "            \n",
    "            all_stats[trial_type] = trial_stats\n",
    "        \n",
    "        # FIXED: Add column headers at the top\n",
    "        for col, condition_name in enumerate(condition_names):\n",
    "            fig.text(0.25 + col * 0.5, 0.95, condition_name, ha='center', va='bottom', \n",
    "                    fontsize=14, fontweight='bold', transform=fig.transFigure)\n",
    "        \n",
    "        # Overall title\n",
    "        fig.suptitle(f'Stride Length Change Distributions\\\\n'\n",
    "                    f'Subject: {subject_id} (Age: {subject_age:.1f} years)', \n",
    "                    fontsize=16, fontweight='bold', y=0.98)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.94])  # Leave space for title and headers\n",
    "        \n",
    "        # Save figure\n",
    "        if save:\n",
    "            filename = f\"stride_change_{subject_id}_fixed_grid.png\"\n",
    "            save_dir = self.individual_plots_dir / \"stride_change_after_success_vs_failure\"\n",
    "            save_dir.mkdir(parents=True, exist_ok=True)\n",
    "            plt.savefig(save_dir / filename, dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n",
    "        \n",
    "        plt.close()  # Close to save memory\n",
    "        \n",
    "        return all_stats\n",
    "\n",
    "    def _plot_distribution(self, ax, data, color, label, alpha):\n",
    "        \"\"\"Helper method to plot distributions with KDE or fallback.\"\"\"\n",
    "        try:\n",
    "            if len(data) >= 2:\n",
    "                kde = gaussian_kde(data)\n",
    "                x_min, x_max = data.min(), data.max()\n",
    "                x_range = x_max - x_min\n",
    "                if x_range > 0:\n",
    "                    x_min -= x_range * 0.1\n",
    "                    x_max += x_range * 0.1\n",
    "                else:\n",
    "                    x_min -= 0.1\n",
    "                    x_max += 0.1\n",
    "                \n",
    "                x_smooth = np.linspace(x_min, x_max, 200)\n",
    "                y_smooth = kde(x_smooth)\n",
    "                \n",
    "                ax.plot(x_smooth, y_smooth, color=color, linewidth=3, alpha=0.8, label=label)\n",
    "                ax.fill_between(x_smooth, y_smooth, alpha=alpha*0.5, color=color)\n",
    "            else:\n",
    "                for i, val in enumerate(data):\n",
    "                    ax.axvline(val, color=color, alpha=0.7, linewidth=2,\n",
    "                              label=label if i == 0 else \"\")\n",
    "        except Exception:\n",
    "            # Fallback to histogram\n",
    "            if len(data) >= 2:\n",
    "                ax.hist(data, bins=min(10, len(data)), alpha=alpha, color=color, \n",
    "                        label=label, density=True, edgecolor='black', linewidth=0.5)\n",
    "            else:\n",
    "                for i, val in enumerate(data):\n",
    "                    ax.axvline(val, color=color, alpha=0.7, linewidth=3,\n",
    "                              label=label if i == 0 else \"\")\n",
    "\n",
    "    def _save_stride_analysis_summary(self, all_stats: Dict) -> None:\n",
    "        \"\"\"Save summary of stride analysis to CSV.\"\"\"\n",
    "        \n",
    "        summary_rows = []\n",
    "        \n",
    "        for subject_id, subject_data in all_stats.items():\n",
    "            base_row = {\n",
    "                'subject_id': subject_id,\n",
    "                'age': subject_data.get('age', np.nan)\n",
    "            }\n",
    "            \n",
    "            for trial_type in ['vis1', 'invis', 'vis2']:\n",
    "                if trial_type in subject_data:\n",
    "                    trial_data = subject_data[trial_type]\n",
    "                    for condition in ['max', 'min']:\n",
    "                        row = base_row.copy()\n",
    "                        row['trial_type'] = trial_type\n",
    "                        row['condition'] = condition\n",
    "                        \n",
    "                        # Add condition-specific data\n",
    "                        for key, value in trial_data.items():\n",
    "                            if key.startswith(f'{condition}_'):\n",
    "                                clean_key = key.replace(f'{condition}_', '')\n",
    "                                row[clean_key] = value\n",
    "                        \n",
    "                        summary_rows.append(row)\n",
    "        \n",
    "        if summary_rows:\n",
    "            summary_df = pd.DataFrame(summary_rows)\n",
    "            summary_path = self.individual_plots_dir / 'stride_analysis_summary.csv'\n",
    "            summary_df.to_csv(summary_path, index=False)\n",
    "            print(f\"📊 Stride analysis summary saved to: {summary_path}\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # UTILITY METHODS\n",
    "    # ==========================================================================\n",
    "\n",
    "    def _add_trendline(self, ax, x, y):\n",
    "        \"\"\"Add trendline with correlation coefficient to plot.\"\"\"\n",
    "        x_clean = pd.to_numeric(x, errors='coerce')\n",
    "        y_clean = pd.to_numeric(y, errors='coerce')\n",
    "        valid = x_clean.notna() & y_clean.notna()\n",
    "        \n",
    "        if valid.sum() < 2:\n",
    "            return\n",
    "        \n",
    "        x_vals = x_clean[valid]\n",
    "        y_vals = y_clean[valid]\n",
    "        \n",
    "        try:\n",
    "            # Fit line\n",
    "            coeffs = np.polyfit(x_vals, y_vals, 1)\n",
    "            trendline = np.poly1d(coeffs)\n",
    "            \n",
    "            # Calculate correlation\n",
    "            r, p = pearsonr(x_vals, y_vals)\n",
    "            \n",
    "            # Plot trendline\n",
    "            ax.plot(x_vals, trendline(x_vals), 'r--', alpha=0.8, linewidth=2)\n",
    "            \n",
    "            # Add correlation text\n",
    "            ax.text(0.05, 0.95, f'r² = {r**2:.3f}\\\\np = {p:.3f}\\\\nn = {len(x_vals)}', \n",
    "                   transform=ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                   verticalalignment='top', fontsize=10)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not add trendline: {e}\")\n",
    "\n",
    "# ==========================================================================\n",
    "# STREAMLINED PIPELINE CLASS (Updated to use consolidated visualizer)\n",
    "# ==========================================================================\n",
    "\n",
    "class StreamlinedMotorLearningPipeline:\n",
    "    \"\"\"\n",
    "    Streamlined pipeline that uses the consolidated StandaloneEnhancedVisualizer.\n",
    "    All plotting methods have been moved to the visualizer class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, analysis_instance, output_dir: str = 'motor_learning_analysis'):\n",
    "        \"\"\"\n",
    "        Initialize with your existing analysis instance.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        analysis_instance : Your existing analysis object\n",
    "            Should have .data_manager, .metrics_df attributes\n",
    "        output_dir : str\n",
    "            Directory to save all outputs\n",
    "        \"\"\"\n",
    "        \n",
    "        self.analysis = analysis_instance\n",
    "        self.data_manager = analysis_instance.data_manager\n",
    "        self.metrics_df = analysis_instance.metrics_df\n",
    "        self.output_dir = Path(output_dir)\n",
    "        \n",
    "        # Create output directory structure\n",
    "        self._setup_output_directories()\n",
    "        \n",
    "        # Use the consolidated enhanced visualizer\n",
    "        self.visualizer = StandaloneEnhancedVisualizer(analysis_instance)\n",
    "        \n",
    "        # Set configuration\n",
    "        self.config = self._get_default_config()\n",
    "        \n",
    "        # Initialize containers\n",
    "        self.analysis_results = {}\n",
    "        self.quality_report = {}\n",
    "        \n",
    "        # Analysis timestamp\n",
    "        self.analysis_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        print(f\"🚀 Streamlined Motor Learning Pipeline initialized\")\n",
    "        print(f\"📊 Data: {len(self.metrics_df)} subjects with {len(self.metrics_df.columns)} metrics\")\n",
    "        print(f\"📁 Output directory: {self.output_dir}\")\n",
    "        print(f\"🎨 Using consolidated enhanced visualizer with ALL plotting methods\")\n",
    "\n",
    "    def _setup_output_directories(self):\n",
    "        \"\"\"Create organized output directory structure.\"\"\"\n",
    "        \n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Create subdirectories\n",
    "        self.dirs = {\n",
    "            'figures': self.output_dir / 'figures',\n",
    "            'individual_plots': self.output_dir / 'figures' / 'individual_plots',\n",
    "            'population_plots': self.output_dir / 'figures' / 'population_plots',\n",
    "            'statistical_plots': self.output_dir / 'figures' / 'statistical_plots',\n",
    "            'reports': self.output_dir / 'reports',\n",
    "            'exports': self.output_dir / 'exports'\n",
    "        }\n",
    "        \n",
    "        for dir_path in self.dirs.values():\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def _get_default_config(self) -> Dict:\n",
    "        \"\"\"Get default configuration parameters.\"\"\"\n",
    "        \n",
    "        return {\n",
    "            'motor_noise_threshold': 0.3,\n",
    "            'success_rate_threshold': 0.68,\n",
    "            'figure_dpi': 300,\n",
    "            'alpha_level': 0.05,\n",
    "            'age_bins': [7, 10, 13, 16, 18],\n",
    "            'age_labels': ['7-10', '10-13', '13-16', '16-18'],\n",
    "            'max_individual_subjects': None  # None = all subjects\n",
    "        }\n",
    "\n",
    "    def run_complete_analysis(self, include_individual_plots: bool = False) -> Dict:\n",
    "        \"\"\"\n",
    "        Run the complete integrated analysis pipeline using the consolidated visualizer.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        include_individual_plots : bool, default False\n",
    "            Whether to generate individual participant plots (time-consuming)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        Dict : Complete analysis results\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"🔄 Starting streamlined analysis pipeline with consolidated visualizer\")\n",
    "        print(f\"⏰ Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"🎯 Individual plots: {'Enabled' if include_individual_plots else 'Disabled'}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        results = {\n",
    "            'timestamp': self.analysis_timestamp,\n",
    "            'steps_completed': [],\n",
    "            'step_results': {},\n",
    "            'include_individual_plots': include_individual_plots\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Quality control analysis\n",
    "            print(\"\\\\n🔍 STEP 1: QUALITY CONTROL ANALYSIS\")\n",
    "            print(\"-\" * 50)\n",
    "            step_result = self._step_quality_control()\n",
    "            results['step_results']['quality_control'] = step_result\n",
    "            results['steps_completed'].append('quality_control')\n",
    "            \n",
    "            # Step 2: Generate ALL visualizations using consolidated visualizer\n",
    "            print(\"\\\\n📈 STEP 2: GENERATING ALL ENHANCED VISUALIZATIONS\")\n",
    "            print(\"-\" * 50)\n",
    "            viz_result = self.visualizer.generate_all_enhanced_plots(\n",
    "                include_individual_plots=include_individual_plots\n",
    "            )\n",
    "            results['step_results']['visualizations'] = viz_result\n",
    "            results['steps_completed'].append('visualizations')\n",
    "            \n",
    "            # Step 3: Export results\n",
    "            print(\"\\\\n💾 STEP 3: EXPORTING RESULTS\")\n",
    "            print(\"-\" * 50)\n",
    "            step_result = self._step_export_results()\n",
    "            results['step_results']['export_results'] = step_result\n",
    "            results['steps_completed'].append('export_results')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\\\n❌ Pipeline failed: {e}\")\n",
    "            results['error'] = str(e)\n",
    "            raise\n",
    "        \n",
    "        # Final summary\n",
    "        print(\"\\\\n\" + \"=\" * 80)\n",
    "        print(\"🎉 STREAMLINED PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"⏰ Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"✅ Steps completed: {len(results['steps_completed'])}/3\")\n",
    "        print(f\"📁 Results saved to: {self.output_dir}\")\n",
    "        \n",
    "        if not include_individual_plots:\n",
    "            print(\"💡 To generate individual plots, rerun with: pipeline.run_complete_analysis(include_individual_plots=True)\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def _step_quality_control(self) -> Dict:\n",
    "        \"\"\"Step 1: Perform quality control analysis.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            df = self.metrics_df\n",
    "            \n",
    "            # Apply motor noise filter\n",
    "            if 'mot_noise' in df.columns:\n",
    "                before_filter = len(df)\n",
    "                filtered_df = df[df['mot_noise'] <= self.config['motor_noise_threshold']]\n",
    "                after_filter = len(filtered_df)\n",
    "                \n",
    "                print(f\"🔍 Motor noise filter (≤ {self.config['motor_noise_threshold']}):\") \n",
    "                print(f\"   Before: {before_filter} subjects\")\n",
    "                print(f\"   After: {after_filter} subjects\") \n",
    "                print(f\"   Excluded: {before_filter - after_filter} subjects ({100*(before_filter-after_filter)/before_filter:.1f}%)\")\n",
    "                \n",
    "                self.quality_report['motor_noise_filter'] = {\n",
    "                    'threshold': self.config['motor_noise_threshold'],\n",
    "                    'before': before_filter,\n",
    "                    'after': after_filter,\n",
    "                    'excluded': before_filter - after_filter,\n",
    "                    'exclusion_rate': (before_filter - after_filter) / before_filter\n",
    "                }\n",
    "            else:\n",
    "                filtered_df = df\n",
    "                print(\"⚠️ No motor noise data available for filtering\")\n",
    "            \n",
    "            # Basic data summary\n",
    "            print(f\"\\\\n📊 Final dataset summary:\")\n",
    "            print(f\"   Total subjects: {len(filtered_df)}\")\n",
    "            if 'age' in filtered_df.columns:\n",
    "                print(f\"   Age range: {filtered_df['age'].min():.1f} - {filtered_df['age'].max():.1f} years\")\n",
    "                print(f\"   Mean age: {filtered_df['age'].mean():.1f} ± {filtered_df['age'].std():.1f} years\")\n",
    "            \n",
    "            # Count success rate measures\n",
    "            sr_cols = [col for col in filtered_df.columns if '_sr_' in col]\n",
    "            print(f\"   Success rate measures: {len(sr_cols)}\")\n",
    "            \n",
    "            self.quality_report.update({\n",
    "                'final_sample_size': len(filtered_df),\n",
    "                'n_success_rate_measures': len(sr_cols)\n",
    "            })\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'filtered_sample_size': len(filtered_df),\n",
    "                'quality_report': self.quality_report\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Quality control failed: {e}\")\n",
    "            return {'success': False, 'error': str(e)}\n",
    "\n",
    "    def _step_export_results(self) -> Dict:\n",
    "        \"\"\"Step 3: Export results and generate reports.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            exported_files = []\n",
    "            \n",
    "            # 1. Export metrics CSV\n",
    "            metrics_file = self.dirs['exports'] / f'metrics_{self.analysis_timestamp}.csv'\n",
    "            self.metrics_df.to_csv(metrics_file, index=False)\n",
    "            exported_files.append(str(metrics_file))\n",
    "            print(f\"📊 Metrics CSV: {metrics_file.name}\")\n",
    "            \n",
    "            # 2. Export quality report\n",
    "            quality_file = self.dirs['reports'] / f'quality_report_{self.analysis_timestamp}.json'\n",
    "            with open(quality_file, 'w') as f:\n",
    "                json.dump(self._make_json_serializable(self.quality_report), f, indent=2)\n",
    "            exported_files.append(str(quality_file))\n",
    "            print(f\"🔍 Quality report: {quality_file.name}\")\n",
    "            \n",
    "            # 3. Generate HTML report\n",
    "            report_file = self._generate_html_report()\n",
    "            exported_files.append(str(report_file))\n",
    "            print(f\"📄 HTML report: {report_file.name}\")\n",
    "            \n",
    "            print(f\"\\\\n✅ Exported {len(exported_files)} files\")\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'exported_files': exported_files,\n",
    "                'n_files': len(exported_files)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Export failed: {e}\")\n",
    "            return {'success': False, 'error': str(e)}\n",
    "\n",
    "    def _generate_html_report(self) -> Path:\n",
    "        \"\"\"Generate HTML report of the analysis.\"\"\"\n",
    "        \n",
    "        html_content = f\"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>Enhanced Motor Learning Analysis Report</title>\n",
    "            <style>\n",
    "                body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
    "                h1 {{ color: #2c3e50; }}\n",
    "                h2 {{ color: #34495e; border-bottom: 2px solid #ecf0f1; padding-bottom: 10px; }}\n",
    "                .metric {{ background-color: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; }}\n",
    "                .highlight {{ background-color: #e8f5e8; padding: 10px; border-left: 4px solid #28a745; }}\n",
    "                table {{ border-collapse: collapse; width: 100%; }}\n",
    "                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "                th {{ background-color: #f2f2f2; }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>Enhanced Motor Learning Analysis Report</h1>\n",
    "            <p><strong>Generated:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "            <p><strong>Analysis ID:</strong> {self.analysis_timestamp}</p>\n",
    "            \n",
    "            <div class=\"highlight\">\n",
    "                <h3>🎯 Enhanced Features</h3>\n",
    "                <ul>\n",
    "                    <li>✅ ALL plotting methods consolidated in StandaloneEnhancedVisualizer</li>\n",
    "                    <li>✅ Age vs Success Rates by trial/condition with motor noise coloring</li>\n",
    "                    <li>✅ Age vs Stride Variability by trial/condition with motor noise coloring</li>\n",
    "                    <li>✅ Mean Stride Length vs Success Rate by trial/condition with motor noise coloring</li>\n",
    "                    <li>✅ Age vs Mean Stride Length and Error by trial/condition</li>\n",
    "                    <li>✅ Motor Noise vs Success Rates by trial/condition with age coloring</li>\n",
    "                    <li>✅ Comprehensive statistical analysis and feature importance</li>\n",
    "                    <li>✅ Quality control with motor noise filtering</li>\n",
    "                    <li>✅ Individual stride change plots (optional)</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            \n",
    "            <h2>Dataset Overview</h2>\n",
    "            <div class=\"metric\">\n",
    "                <strong>Total Subjects:</strong> {len(self.metrics_df)}<br>\n",
    "                <strong>Filtered Subjects:</strong> {len(self.metrics_df[self.metrics_df['mot_noise'] <= self.config['motor_noise_threshold']]) if 'mot_noise' in self.metrics_df.columns else 'N/A'}<br>\n",
    "                <strong>Age Range:</strong> {self.metrics_df['age'].min():.1f} - {self.metrics_df['age'].max():.1f} years<br>\n",
    "                <strong>Motor Noise Threshold:</strong> {self.config['motor_noise_threshold']}\n",
    "            </div>\n",
    "            \n",
    "            <h2>Quality Control Results</h2>\n",
    "            <div class=\"metric\">\n",
    "                {self._format_quality_report_html()}\n",
    "            </div>\n",
    "            \n",
    "            <h2>Generated Visualizations</h2>\n",
    "            <div class=\"metric\">\n",
    "                <strong>Enhanced Population Plots:</strong><br>\n",
    "                • age_vs_success_rates_enhanced.png<br>\n",
    "                • age_vs_stride_variability_enhanced.png<br>\n",
    "                • mean_stride_length_vs_success_rate.png<br>\n",
    "                • age_vs_mean_stride_length_enhanced.png<br>\n",
    "                • age_vs_mean_error_enhanced.png<br>\n",
    "                • mean_error_vs_success_rate_enhanced.png<br>\n",
    "                • motor_noise_vs_success_rates_enhanced.png<br>\n",
    "                • age_vs_motor_noise.png<br>\n",
    "                • correlation_matrix.png<br>\n",
    "                • success_rate_overview.png<br><br>\n",
    "                \n",
    "                <strong>Statistical Analysis Plots:</strong><br>\n",
    "                • feature_importance_analysis.png<br>\n",
    "                • age_effects_summary.png<br>\n",
    "                • trial_comparisons.png<br>\n",
    "                • analysis_dashboard.png<br><br>\n",
    "                \n",
    "                <strong>Individual Plots (if enabled):</strong><br>\n",
    "                • Individual stride change distributions for each participant<br>\n",
    "                • Stride analysis summary CSV\n",
    "            </div>\n",
    "            \n",
    "            <h2>Files Generated</h2>\n",
    "            <div class=\"metric\">\n",
    "                <strong>Output Directory:</strong> {self.output_dir}<br>\n",
    "                <strong>Figures:</strong> {self.dirs['figures']}<br>\n",
    "                <strong>Reports:</strong> {self.dirs['reports']}<br>\n",
    "                <strong>Exports:</strong> {self.dirs['exports']}<br>\n",
    "                <strong>Consolidated Visualizer:</strong> All plotting methods now in StandaloneEnhancedVisualizer\n",
    "            </div>\n",
    "            \n",
    "            <h2>Usage Instructions</h2>\n",
    "            <div class=\"metric\">\n",
    "                <strong>To use the consolidated visualizer directly:</strong><br>\n",
    "                <code>\n",
    "                # Create enhanced visualizer<br>\n",
    "                enhanced_viz = StandaloneEnhancedVisualizer(your_analysis_instance)<br><br>\n",
    "                \n",
    "                # Generate all plots at once<br>\n",
    "                results = enhanced_viz.generate_all_enhanced_plots(include_individual_plots=True)<br><br>\n",
    "                \n",
    "                # Or generate specific plot categories<br>\n",
    "                enhanced_viz.generate_enhanced_population_plots()<br>\n",
    "                enhanced_viz.generate_statistical_plots()<br>\n",
    "                enhanced_viz.generate_summary_dashboard()\n",
    "                </code>\n",
    "            </div>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        report_file = self.dirs['reports'] / f'analysis_report_{self.analysis_timestamp}.html'\n",
    "        with open(report_file, 'w') as f:\n",
    "            f.write(html_content)\n",
    "        \n",
    "        return report_file\n",
    "\n",
    "    def _format_quality_report_html(self) -> str:\n",
    "        \"\"\"Format quality report for HTML.\"\"\"\n",
    "        \n",
    "        if not self.quality_report:\n",
    "            return \"Quality report not available\"\n",
    "        \n",
    "        html_parts = []\n",
    "        \n",
    "        if 'motor_noise_filter' in self.quality_report:\n",
    "            filter_data = self.quality_report['motor_noise_filter']\n",
    "            html_parts.append(f\"\"\"\n",
    "                <strong>Motor Noise Filtering:</strong><br>\n",
    "                • Before filtering: {filter_data['before']} subjects<br>\n",
    "                • After filtering: {filter_data['after']} subjects<br>\n",
    "                • Exclusion rate: {filter_data['exclusion_rate']*100:.1f}%\n",
    "            \"\"\")\n",
    "        \n",
    "        if 'final_sample_size' in self.quality_report:\n",
    "            html_parts.append(f\"<strong>Final Sample Size:</strong> {self.quality_report['final_sample_size']} subjects\")\n",
    "        \n",
    "        return \"<br><br>\".join(html_parts) if html_parts else \"Quality metrics not available\"\n",
    "\n",
    "    def _make_json_serializable(self, obj):\n",
    "        \"\"\"Convert numpy types to Python types for JSON serialization.\"\"\"\n",
    "        \n",
    "        if isinstance(obj, dict):\n",
    "            return {key: self._make_json_serializable(value) for key, value in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [self._make_json_serializable(item) for item in obj]\n",
    "        elif isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif pd.isna(obj):\n",
    "            return None\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "# ==========================================================================\n",
    "# USAGE EXAMPLE\n",
    "# ==========================================================================\n",
    "\n",
    "def demonstrate_consolidated_visualizer():\n",
    "    \"\"\"\n",
    "    Example of how to use the consolidated enhanced visualizer.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🎨 CONSOLIDATED ENHANCED VISUALIZER DEMONSTRATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    print(\"🔧 Step 1: Create your analysis instance (existing code)\")\n",
    "    print(\"# analysis = MotorLearningAnalysis(data_manager, metrics_df)\")\n",
    "    print()\n",
    "    \n",
    "    print(\"🎨 Step 2: Create consolidated enhanced visualizer\")\n",
    "    print(\"# enhanced_viz = StandaloneEnhancedVisualizer(analysis)\")\n",
    "    print()\n",
    "    \n",
    "    print(\"📊 Step 3: Generate ALL plots in one call\")\n",
    "    print(\"# results = enhanced_viz.generate_all_enhanced_plots(include_individual_plots=True)\")\n",
    "    print()\n",
    "    \n",
    "    print(\"🎯 OR generate specific plot categories:\")\n",
    "    print(\"# enhanced_viz.generate_enhanced_population_plots()\")\n",
    "    print(\"# enhanced_viz.generate_statistical_plots()\")\n",
    "    print(\"# enhanced_viz.generate_summary_dashboard()\")\n",
    "    print()\n",
    "    \n",
    "    print(\"🚀 OR use the streamlined pipeline (uses consolidated visualizer internally)\")\n",
    "    print(\"# pipeline = StreamlinedMotorLearningPipeline(analysis)\")\n",
    "    print(\"# results = pipeline.run_complete_analysis(include_individual_plots=True)\")\n",
    "    print()\n",
    "    \n",
    "    print(\"✅ ALL plotting methods are now consolidated in StandaloneEnhancedVisualizer!\")\n",
    "    print(\"📁 Organized output directories with enhanced plots\")\n",
    "    print(\"🎨 Motor noise coloring, age effects, trial comparisons, and more\")\n",
    "    print(\"📊 Statistical analysis plots and comprehensive dashboard\")\n",
    "    print(\"🎯 Optional individual stride change plots for detailed analysis\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demonstrate_consolidated_visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93de7f34-6d91-4e46-a2e0-3ba4aecad35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Config initialized with base directory: analysis\n",
      "   📊 Figures: analysis\\figures\n",
      "   📋 Reports: analysis\\reports\n",
      "   💾 Exports: analysis\\exports\n",
      "🧮 Calculating metrics for 66 subjects...\n",
      "   Processed 20/66 subjects...\n",
      "   Processed 40/66 subjects...\n",
      "   Processed 60/66 subjects...\n",
      "✅ Successfully calculated metrics for 66 subjects\n",
      "📊 Age range: 7.2 - 17.9 years\n",
      "🎯 Success rate columns created: ['vis1_sr_max_const', 'vis1_sr_min_const', 'invis_sr_max_const', 'invis_sr_min_const', 'vis2_sr_max_const', 'vis2_sr_min_const']\n",
      "📊 Filtered to 64/66 subjects (motor noise ≤ 0.3)\n",
      "📊 Using 64/66 subjects (motor noise ≤ 0.3)\n",
      "✅ Enhanced visualizer initialized with consolidated plotting methods\n",
      "📁 Individual plots: analysis\\figures\\individual_plots\n",
      "📁 Population plots: analysis\\figures\\population_plots\n",
      "📁 Statistical plots: analysis\\figures\\statistical_plots\n",
      "✅ Analysis ready! 66 subjects loaded.\n",
      "📁 All outputs will be saved to: analysis\n",
      "🎯 Visualizer initialized successfully: True\n"
     ]
    }
   ],
   "source": [
    "# CORRECTED USAGE CODE\n",
    "# The issue was passing config instead of a string path\n",
    "\n",
    "METADATA_PATH = \"muh_metadata.csv\"\n",
    "DATA_ROOT_DIR = \"muh_data/\"\n",
    "\n",
    "# 1. Create centralized config\n",
    "config = Config('analysis')\n",
    "\n",
    "# 2. Create data manager with config\n",
    "data_manager = MotorLearningDataManager(\n",
    "    METADATA_PATH, \n",
    "    DATA_ROOT_DIR, \n",
    "    config=config, \n",
    "    debug=True\n",
    ")\n",
    "\n",
    "data_manager = data_manager.filter_trials(required_trial_types=['vis1', 'invis', 'vis2'])\n",
    "\n",
    "# 3. Calculate metrics\n",
    "metrics_calculator = MetricsCalculator(data_manager)\n",
    "metrics_df = metrics_calculator.calculate_all_metrics()\n",
    "\n",
    "# 4. Create analysis with shared config\n",
    "analysis = MotorLearningAnalysis(data_manager, metrics_df)\n",
    "\n",
    "print(f\"✅ Analysis ready! {len(metrics_df)} subjects loaded.\")\n",
    "print(f\"📁 All outputs will be saved to: {config.BASE_OUTPUT_DIR}\")\n",
    "print(f\"🎯 Visualizer initialized successfully: {hasattr(analysis.visualizer, 'individual_plots_dir')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4410bbb5-21a7-4925-b912-8158816d4596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Using 64/66 subjects (motor noise ≤ 0.3)\n",
      "✅ Enhanced visualizer initialized with consolidated plotting methods\n",
      "📁 Individual plots: analysis\\figures\\individual_plots\n",
      "📁 Population plots: analysis\\figures\\population_plots\n",
      "📁 Statistical plots: analysis\\figures\\statistical_plots\n",
      "🚀 Streamlined Motor Learning Pipeline initialized\n",
      "📊 Data: 66 subjects with 58 metrics\n",
      "📁 Output directory: analysis\n",
      "🎨 Using consolidated enhanced visualizer with ALL plotting methods\n",
      "✅ Pipeline ready!\n",
      "\n",
      "🚀 Running integrated analysis pipeline...\n",
      "🔄 Starting streamlined analysis pipeline with consolidated visualizer\n",
      "⏰ Started at: 2025-06-03 11:48:39\n",
      "🎯 Individual plots: Disabled\n",
      "================================================================================\n",
      "\\n🔍 STEP 1: QUALITY CONTROL ANALYSIS\n",
      "--------------------------------------------------\n",
      "🔍 Motor noise filter (≤ 0.3):\n",
      "   Before: 66 subjects\n",
      "   After: 64 subjects\n",
      "   Excluded: 2 subjects (3.0%)\n",
      "\\n📊 Final dataset summary:\n",
      "   Total subjects: 64\n",
      "   Age range: 7.2 - 17.9 years\n",
      "   Mean age: 12.4 ± 3.2 years\n",
      "   Success rate measures: 6\n",
      "\\n📈 STEP 2: GENERATING ALL ENHANCED VISUALIZATIONS\n",
      "--------------------------------------------------\n",
      "🚀 Starting comprehensive enhanced plotting analysis...\n",
      "⏰ Started at: 2025-06-03 11:48:39\n",
      "🎯 Individual plots: Disabled\n",
      "================================================================================\n",
      "\n",
      "⏭️ Skipping individual plots (set include_individual_plots=True to enable)\n",
      "\n",
      "👥 ENHANCED POPULATION-LEVEL ANALYSIS PLOTS\n",
      "--------------------------------------------------\n",
      "📊 Generating enhanced population-level analysis plots...\n",
      "   🎯 Age vs Success Rates (Enhanced by trial/condition)...\n",
      "   📏 Age vs Stride Variability (Enhanced by trial/condition)...\n",
      "   📊 Mean Stride Length vs Success Rate (by trial/condition)...\n",
      "   📏 Age vs Mean Stride Length (Enhanced by trial/condition)...\n",
      "   🎯 Age vs Mean Error (Enhanced by trial/condition)...\n",
      "   📊 Mean Error vs Success Rate (Enhanced by trial/condition)...\n",
      "   🧠 Motor Noise vs Success Rate (by trial/condition)...\n",
      "   👥 Age vs Motor Noise...\n",
      "   🔗 Correlation Matrix...\n",
      "   📊 Success Rate Overview...\n",
      "   ✅ Generated 10 enhanced population-level plots\n",
      "\n",
      "📊 STATISTICAL ANALYSIS PLOTS\n",
      "--------------------------------------------------\n",
      "📊 Generating statistical analysis plots...\n",
      "   📈 Feature Importance Analysis...\n",
      "   👥 Age Effects Summary...\n",
      "   🎮 Trial Type Comparisons...\n",
      "   ✅ Generated 3 statistical analysis plots\n",
      "\n",
      "📋 SUMMARY DASHBOARD\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\castle\\AppData\\Local\\Temp\\ipykernel_9452\\3420013994.py:1202: UserWarning: Glyph 9989 (\\N{WHITE HEAVY CHECK MARK}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(dashboard_file, dpi=getattr(self.config, 'FIGURE_DPI', 300), bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Generated summary dashboard: analysis_dashboard_20250603_114847.png\n",
      "\n",
      "================================================================================\n",
      "🎉 ENHANCED PLOTTING COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n",
      "⏰ Completed at: 2025-06-03 11:48:48\n",
      "📊 Total plots generated: 13\n",
      "   • Individual plots: 0\n",
      "   • Population plots: 10\n",
      "   • Statistical plots: 3\n",
      "📁 Files saved to: analysis\n",
      "💡 To generate individual plots, use: generate_all_enhanced_plots(include_individual_plots=True)\n",
      "\\n💾 STEP 3: EXPORTING RESULTS\n",
      "--------------------------------------------------\n",
      "📊 Metrics CSV: metrics_20250603_114839.csv\n",
      "🔍 Quality report: quality_report_20250603_114839.json\n",
      "❌ Export failed: 'charmap' codec can't encode character '\\U0001f3af' in position 1093: character maps to <undefined>\n",
      "\\n================================================================================\n",
      "🎉 STREAMLINED PIPELINE COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n",
      "⏰ Completed at: 2025-06-03 11:48:48\n",
      "✅ Steps completed: 3/3\n",
      "📁 Results saved to: analysis\n",
      "💡 To generate individual plots, rerun with: pipeline.run_complete_analysis(include_individual_plots=True)\n"
     ]
    }
   ],
   "source": [
    "# 5. CORRECTED: Create integrated pipeline with STRING output directory\n",
    "# Option 1: Use the same directory as config\n",
    "pipeline = StreamlinedMotorLearningPipeline(analysis, str(config.BASE_OUTPUT_DIR))\n",
    "\n",
    "# OR Option 2: Use a different directory name\n",
    "# pipeline = IntegratedMotorLearningPipeline(analysis, 'integrated_analysis_output')\n",
    "\n",
    "print(f\"✅ Pipeline ready!\")\n",
    "\n",
    "# 6. Run the full pipeline\n",
    "print(\"\\n🚀 Running integrated analysis pipeline...\")\n",
    "pipeline_results = pipeline.run_complete_analysis(include_individual_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7618079a-595a-4063-a648-dd47c0dcbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_results = pipeline.predict_stride_error_simple(pipeline.metrics_df)\n",
    "pipeline.plot_prediction_results_simple(prediction_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6162ccb-394a-4c39-8eba-1343c934d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run powerpoint_auto_generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d9e96-9ed0-41dd-86b1-3dde87098523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
